{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5105 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1080 (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "from scipy.stats import itemfreq\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "FILE_PATH = '/home/sam/Hhd/twitter_sentiment/'\n",
    "# FILE_PATH = '/home/sam/Data/twitter_sentiment/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "pos_array = np.load(FILE_PATH+'pos.npy')\n",
    "neg_array = np.load(FILE_PATH+'neg.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2183, 20, 800)\n",
      "(2416, 20, 800)\n",
      "(4599, 1, 20, 800)\n",
      "(4599,)\n"
     ]
    }
   ],
   "source": [
    "print pos_array.shape\n",
    "print neg_array.shape\n",
    "data = np.concatenate([pos_array, neg_array])\n",
    "N, M, D = data.shape\n",
    "data = data.reshape(-1, 1, M, D).astype(theano.config.floatX)\n",
    "label = np.concatenate([np.ones(pos_array.shape[0]), np.ones(neg_array.shape[0])+1]) # 1 for positive, 2 for negative\n",
    "label = np.int8(label)-1\n",
    "print data.shape\n",
    "print label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ############################# Batch iterator ###############################\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ##################### Build the CNN neural network model #######################\n",
    "def build_cnn(input_var=None):\n",
    "    # We create a CNN of two convolution + pooling stages\n",
    "    # and a fully-connected hidden layer in front of the output layer.\n",
    "\n",
    "    # Input layer, as usual:\n",
    "    network = lasagne.layers.InputLayer(shape=(None, 1, M, D), input_var=input_var)\n",
    "    # This time we do not apply input dropout, as it tends to work less well\n",
    "    # for convolutional layers.\n",
    "\n",
    "    # Convolutional layer with 32 kernels of size 3x3. Strided and padded\n",
    "    # convolutions are supported as well; see the docstring.\n",
    "    network = lasagne.layers.Conv2DLayer(network, num_filters=32, filter_size=(3, 3), \\\n",
    "                                         nonlinearity=lasagne.nonlinearities.rectify, \\\n",
    "                                         W=lasagne.init.GlorotUniform(), pad=1, stride=(1, 1), \\\n",
    "                                         untie_biases=True)\n",
    "    # Max-pooling layer of factor 2 in both dimensions:\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "\n",
    "    # Another convolution with 32 3x3 kernels, and another 2x2 pooling:\n",
    "    network = lasagne.layers.Conv2DLayer(network, num_filters=32, filter_size=(3, 3), \\\n",
    "                                         nonlinearity=lasagne.nonlinearities.rectify, pad=1, \\\n",
    "                                         stride=(1, 1), untie_biases=True)\n",
    "    \n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "\n",
    "    # A fully-connected layer of ??? units with 50% dropout on its inputs:\n",
    "    network = lasagne.layers.DenseLayer(lasagne.layers.dropout(network, p=0.5), num_units=2000, \\\n",
    "                                        nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    # And, finally, the 10-unit output layer with 50% dropout on its inputs:\n",
    "    network = lasagne.layers.DenseLayer(lasagne.layers.dropout(network, p=0.5), num_units=2,  \\\n",
    "                                        nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ############################## Main program ################################\n",
    "def train_cnn(X_train, y_train, X_val, y_val, X_test, num_epochs=500):\n",
    "    # Load the dataset\n",
    "    print(\"Loading data...\")\n",
    "    #X_train, y_train, X_val, y_val, X_test = load_dataset()\n",
    "    # Prepare Theano variables for inputs and targets\n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    # Create neural network model (depending on first command line parameter)\n",
    "    print(\"Building model and compiling functions...\")\n",
    "\n",
    "    network = build_cnn(input_var)\n",
    "    accuracy_rate = []\n",
    "\n",
    "    # Create a loss expression for training, i.e., a scalar objective we want\n",
    "    # to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "    # We could add some weight decay as well here, see lasagne.regularization.\n",
    "\n",
    "    # Create update expressions for training, i.e., how to modify the\n",
    "    # parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "    # Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=0.001, momentum=0.9)\n",
    "\n",
    "    # Create a loss expression for validation/testing. The crucial difference\n",
    "    # here is that we do a deterministic forward pass through the network,\n",
    "    # disabling dropout layers.\n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    # print test_prediction.flatten()\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction, target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "    # As a bonus, also create an expression for the classification accuracy:\n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var), dtype=theano.config.floatX)\n",
    "\n",
    "    predict_label = T.argmax(test_prediction,axis=1)\n",
    "\n",
    "    # Compile a function performing a training step on a mini-batch (by giving\n",
    "    # the updates dictionary) and returning the corresponding training loss:\n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "    # Compile a second function computing the validation loss and accuracy:\n",
    "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "    test_fn = theano.function([input_var], predict_label)\n",
    "\n",
    "    # Finally, launch the training loop.\n",
    "    print(\"Starting training...\")\n",
    "    # We iterate over epochs:\n",
    "    for epoch in range(num_epochs):\n",
    "#         start_time = time.time()\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        for batch in iterate_minibatches(X_train, y_train, 50, shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            train_batches += 1\n",
    "    \n",
    "#         train_err = train_fn(X_train, y_train)\n",
    "        # And a full pass over the validation data:\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(X_val, y_val, 50, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "    \n",
    "#         val_err, val_acc = val_fn(X_val, y_val)\n",
    "#         accuracy_rate.append(val_acc)\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "        print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "        print(\"  validation accuracy:\\t\\t{:.2f} %\".format(val_acc / val_batches * 100))\n",
    "\n",
    "            \n",
    "    # After training, we compute and print the test error:\n",
    "    test_pred = test_fn(X_test)\n",
    "    print set(test_pred)\n",
    "\n",
    "    # After training, we compute and print the test error:\n",
    "#     test_err = 0\n",
    "#     test_acc = 0\n",
    "#     test_batches = 0\n",
    "#     for batch in iterate_minibatches(X_test, y_test, 500, shuffle=False):\n",
    "#         inputs, targets = batch\n",
    "#         err, acc = val_fn(inputs, targets)\n",
    "#         test_err += err\n",
    "#         test_acc += acc\n",
    "#         test_batches += 1\n",
    "#     print(\"Final results:\")\n",
    "#     print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "#     print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "#         test_acc / test_batches * 100))\n",
    "\n",
    "    # Optionally, you could now dump the network weights to a file like this:\n",
    "    # np.savez('model.npz', *lasagne.layers.get_all_param_values(network))\n",
    "    #\n",
    "    # And load them again later on like this:\n",
    "    # with np.load('model.npz') as f:\n",
    "    #     param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    # lasagne.layers.set_all_param_values(network, param_values)\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TRAIN:', array([ 728,  729,  730, ..., 4596, 4597, 4598]), 'TEST:', array([   0,    1,    2, ..., 2986, 2987, 2988]))\n",
      "train freq [1455 1610]\n",
      "val freq [728 806]\n",
      "Loading data...\n",
      "Building model and compiling functions...\n",
      "Starting training...\n",
      "Epoch 1 of 500 took 2.183s\n",
      "  training loss:\t\t0.692695\n",
      "  validation loss:\t\t0.692443\n",
      "  validation accuracy:\t\t51.47 %\n",
      "Epoch 2 of 500 took 2.155s\n",
      "  training loss:\t\t0.691509\n",
      "  validation loss:\t\t0.692160\n",
      "  validation accuracy:\t\t51.47 %\n",
      "Epoch 3 of 500 took 2.128s\n",
      "  training loss:\t\t0.691260\n",
      "  validation loss:\t\t0.691913\n",
      "  validation accuracy:\t\t51.47 %\n",
      "Epoch 4 of 500 took 2.133s\n",
      "  training loss:\t\t0.690653\n",
      "  validation loss:\t\t0.691832\n",
      "  validation accuracy:\t\t51.47 %\n",
      "Epoch 5 of 500 took 2.130s\n",
      "  training loss:\t\t0.689775\n",
      "  validation loss:\t\t0.691506\n",
      "  validation accuracy:\t\t51.47 %\n",
      "Epoch 6 of 500 took 2.103s\n",
      "  training loss:\t\t0.689484\n",
      "  validation loss:\t\t0.691296\n",
      "  validation accuracy:\t\t51.47 %\n",
      "Epoch 7 of 500 took 2.119s\n",
      "  training loss:\t\t0.689052\n",
      "  validation loss:\t\t0.691076\n",
      "  validation accuracy:\t\t51.47 %\n",
      "Epoch 8 of 500 took 2.216s\n",
      "  training loss:\t\t0.688588\n",
      "  validation loss:\t\t0.690932\n",
      "  validation accuracy:\t\t51.33 %\n",
      "Epoch 9 of 500 took 2.232s\n",
      "  training loss:\t\t0.688522\n",
      "  validation loss:\t\t0.690756\n",
      "  validation accuracy:\t\t52.00 %\n",
      "Epoch 10 of 500 took 2.210s\n",
      "  training loss:\t\t0.687902\n",
      "  validation loss:\t\t0.690664\n",
      "  validation accuracy:\t\t52.73 %\n",
      "Epoch 11 of 500 took 2.160s\n",
      "  training loss:\t\t0.687376\n",
      "  validation loss:\t\t0.690368\n",
      "  validation accuracy:\t\t54.67 %\n",
      "Epoch 12 of 500 took 2.191s\n",
      "  training loss:\t\t0.686821\n",
      "  validation loss:\t\t0.690246\n",
      "  validation accuracy:\t\t54.93 %\n",
      "Epoch 13 of 500 took 2.142s\n",
      "  training loss:\t\t0.686976\n",
      "  validation loss:\t\t0.690194\n",
      "  validation accuracy:\t\t55.13 %\n",
      "Epoch 14 of 500 took 2.103s\n",
      "  training loss:\t\t0.686221\n",
      "  validation loss:\t\t0.690013\n",
      "  validation accuracy:\t\t54.80 %\n",
      "Epoch 15 of 500 took 2.147s\n",
      "  training loss:\t\t0.686282\n",
      "  validation loss:\t\t0.689821\n",
      "  validation accuracy:\t\t54.67 %\n",
      "Epoch 16 of 500 took 2.222s\n",
      "  training loss:\t\t0.685686\n",
      "  validation loss:\t\t0.689593\n",
      "  validation accuracy:\t\t53.73 %\n",
      "Epoch 17 of 500 took 2.219s\n",
      "  training loss:\t\t0.685374\n",
      "  validation loss:\t\t0.689651\n",
      "  validation accuracy:\t\t54.67 %\n",
      "Epoch 18 of 500 took 2.218s\n",
      "  training loss:\t\t0.685124\n",
      "  validation loss:\t\t0.689538\n",
      "  validation accuracy:\t\t55.00 %\n",
      "Epoch 19 of 500 took 2.215s\n",
      "  training loss:\t\t0.684664\n",
      "  validation loss:\t\t0.689258\n",
      "  validation accuracy:\t\t53.53 %\n",
      "Epoch 20 of 500 took 2.213s\n",
      "  training loss:\t\t0.683915\n",
      "  validation loss:\t\t0.689178\n",
      "  validation accuracy:\t\t54.07 %\n",
      "Epoch 21 of 500 took 2.194s\n",
      "  training loss:\t\t0.683257\n",
      "  validation loss:\t\t0.689025\n",
      "  validation accuracy:\t\t54.07 %\n",
      "Epoch 22 of 500 took 2.233s\n",
      "  training loss:\t\t0.683275\n",
      "  validation loss:\t\t0.689064\n",
      "  validation accuracy:\t\t54.73 %\n",
      "Epoch 23 of 500 took 2.189s\n",
      "  training loss:\t\t0.683043\n",
      "  validation loss:\t\t0.688894\n",
      "  validation accuracy:\t\t54.53 %\n",
      "Epoch 24 of 500 took 2.225s\n",
      "  training loss:\t\t0.683102\n",
      "  validation loss:\t\t0.688641\n",
      "  validation accuracy:\t\t54.07 %\n",
      "Epoch 25 of 500 took 2.179s\n",
      "  training loss:\t\t0.682063\n",
      "  validation loss:\t\t0.688491\n",
      "  validation accuracy:\t\t53.53 %\n",
      "Epoch 26 of 500 took 2.167s\n",
      "  training loss:\t\t0.682108\n",
      "  validation loss:\t\t0.688327\n",
      "  validation accuracy:\t\t53.87 %\n",
      "Epoch 27 of 500 took 2.232s\n",
      "  training loss:\t\t0.681852\n",
      "  validation loss:\t\t0.688308\n",
      "  validation accuracy:\t\t54.47 %\n",
      "Epoch 28 of 500 took 2.225s\n",
      "  training loss:\t\t0.681228\n",
      "  validation loss:\t\t0.688125\n",
      "  validation accuracy:\t\t54.27 %\n",
      "Epoch 29 of 500 took 2.183s\n",
      "  training loss:\t\t0.680857\n",
      "  validation loss:\t\t0.687920\n",
      "  validation accuracy:\t\t54.07 %\n",
      "Epoch 30 of 500 took 2.239s\n",
      "  training loss:\t\t0.680535\n",
      "  validation loss:\t\t0.687723\n",
      "  validation accuracy:\t\t53.60 %\n",
      "Epoch 31 of 500 took 2.240s\n",
      "  training loss:\t\t0.679997\n",
      "  validation loss:\t\t0.687545\n",
      "  validation accuracy:\t\t53.53 %\n",
      "Epoch 32 of 500 took 2.229s\n",
      "  training loss:\t\t0.679317\n",
      "  validation loss:\t\t0.687266\n",
      "  validation accuracy:\t\t54.00 %\n",
      "Epoch 33 of 500 took 2.254s\n",
      "  training loss:\t\t0.679460\n",
      "  validation loss:\t\t0.687117\n",
      "  validation accuracy:\t\t54.07 %\n",
      "Epoch 34 of 500 took 2.222s\n",
      "  training loss:\t\t0.678283\n",
      "  validation loss:\t\t0.686972\n",
      "  validation accuracy:\t\t53.80 %\n",
      "Epoch 35 of 500 took 2.162s\n",
      "  training loss:\t\t0.678367\n",
      "  validation loss:\t\t0.686943\n",
      "  validation accuracy:\t\t54.53 %\n",
      "Epoch 36 of 500 took 2.203s\n",
      "  training loss:\t\t0.678023\n",
      "  validation loss:\t\t0.686497\n",
      "  validation accuracy:\t\t54.27 %\n",
      "Epoch 37 of 500 took 2.228s\n",
      "  training loss:\t\t0.677872\n",
      "  validation loss:\t\t0.686432\n",
      "  validation accuracy:\t\t54.47 %\n",
      "Epoch 38 of 500 took 2.227s\n",
      "  training loss:\t\t0.677144\n",
      "  validation loss:\t\t0.686216\n",
      "  validation accuracy:\t\t54.40 %\n",
      "Epoch 39 of 500 took 2.228s\n",
      "  training loss:\t\t0.676232\n",
      "  validation loss:\t\t0.685919\n",
      "  validation accuracy:\t\t54.47 %\n",
      "Epoch 40 of 500 took 2.168s\n",
      "  training loss:\t\t0.675711\n",
      "  validation loss:\t\t0.685723\n",
      "  validation accuracy:\t\t54.60 %\n",
      "Epoch 41 of 500 took 2.160s\n",
      "  training loss:\t\t0.675539\n",
      "  validation loss:\t\t0.685446\n",
      "  validation accuracy:\t\t54.80 %\n",
      "Epoch 42 of 500 took 2.206s\n",
      "  training loss:\t\t0.674860\n",
      "  validation loss:\t\t0.685130\n",
      "  validation accuracy:\t\t54.87 %\n",
      "Epoch 43 of 500 took 2.231s\n",
      "  training loss:\t\t0.674007\n",
      "  validation loss:\t\t0.684726\n",
      "  validation accuracy:\t\t55.27 %\n",
      "Epoch 44 of 500 took 2.230s\n",
      "  training loss:\t\t0.673358\n",
      "  validation loss:\t\t0.684494\n",
      "  validation accuracy:\t\t55.40 %\n",
      "Epoch 45 of 500 took 2.227s\n",
      "  training loss:\t\t0.672585\n",
      "  validation loss:\t\t0.684298\n",
      "  validation accuracy:\t\t55.13 %\n",
      "Epoch 46 of 500 took 2.217s\n",
      "  training loss:\t\t0.672643\n",
      "  validation loss:\t\t0.683990\n",
      "  validation accuracy:\t\t55.27 %\n",
      "Epoch 47 of 500 took 2.225s\n",
      "  training loss:\t\t0.671440\n",
      "  validation loss:\t\t0.683573\n",
      "  validation accuracy:\t\t55.33 %\n",
      "Epoch 48 of 500 took 2.224s\n",
      "  training loss:\t\t0.670832\n",
      "  validation loss:\t\t0.683416\n",
      "  validation accuracy:\t\t55.80 %\n",
      "Epoch 49 of 500 took 2.221s\n",
      "  training loss:\t\t0.670703\n",
      "  validation loss:\t\t0.683240\n",
      "  validation accuracy:\t\t56.47 %\n",
      "Epoch 50 of 500 took 2.202s\n",
      "  training loss:\t\t0.669170\n",
      "  validation loss:\t\t0.682728\n",
      "  validation accuracy:\t\t56.67 %\n",
      "Epoch 51 of 500 took 2.202s\n",
      "  training loss:\t\t0.668921\n",
      "  validation loss:\t\t0.682124\n",
      "  validation accuracy:\t\t55.73 %\n",
      "Epoch 52 of 500 took 2.215s\n",
      "  training loss:\t\t0.667777\n",
      "  validation loss:\t\t0.681875\n",
      "  validation accuracy:\t\t56.27 %\n",
      "Epoch 53 of 500 took 2.156s\n",
      "  training loss:\t\t0.667429\n",
      "  validation loss:\t\t0.681966\n",
      "  validation accuracy:\t\t56.87 %\n",
      "Epoch 54 of 500 took 2.219s\n",
      "  training loss:\t\t0.666788\n",
      "  validation loss:\t\t0.681183\n",
      "  validation accuracy:\t\t56.93 %\n",
      "Epoch 55 of 500 took 2.133s\n",
      "  training loss:\t\t0.665788\n",
      "  validation loss:\t\t0.680662\n",
      "  validation accuracy:\t\t56.67 %\n",
      "Epoch 56 of 500 took 2.188s\n",
      "  training loss:\t\t0.664945\n",
      "  validation loss:\t\t0.680353\n",
      "  validation accuracy:\t\t57.00 %\n",
      "Epoch 57 of 500 took 2.205s\n",
      "  training loss:\t\t0.663726\n",
      "  validation loss:\t\t0.679517\n",
      "  validation accuracy:\t\t57.00 %\n",
      "Epoch 58 of 500 took 2.189s\n",
      "  training loss:\t\t0.663947\n",
      "  validation loss:\t\t0.678998\n",
      "  validation accuracy:\t\t56.07 %\n",
      "Epoch 59 of 500 took 2.183s\n",
      "  training loss:\t\t0.662454\n",
      "  validation loss:\t\t0.678717\n",
      "  validation accuracy:\t\t57.00 %\n",
      "Epoch 60 of 500 took 2.181s\n",
      "  training loss:\t\t0.660948\n",
      "  validation loss:\t\t0.678259\n",
      "  validation accuracy:\t\t57.40 %\n",
      "Epoch 61 of 500 took 2.180s\n",
      "  training loss:\t\t0.659109\n",
      "  validation loss:\t\t0.677578\n",
      "  validation accuracy:\t\t57.67 %\n",
      "Epoch 62 of 500 took 2.182s\n",
      "  training loss:\t\t0.659545\n",
      "  validation loss:\t\t0.676887\n",
      "  validation accuracy:\t\t57.60 %\n",
      "Epoch 63 of 500 took 2.191s\n",
      "  training loss:\t\t0.659292\n",
      "  validation loss:\t\t0.676204\n",
      "  validation accuracy:\t\t58.20 %\n",
      "Epoch 64 of 500 took 2.176s\n",
      "  training loss:\t\t0.656696\n",
      "  validation loss:\t\t0.675545\n",
      "  validation accuracy:\t\t58.13 %\n",
      "Epoch 65 of 500 took 2.175s\n",
      "  training loss:\t\t0.655828\n",
      "  validation loss:\t\t0.674761\n",
      "  validation accuracy:\t\t58.20 %\n",
      "Epoch 66 of 500 took 2.176s\n",
      "  training loss:\t\t0.655159\n",
      "  validation loss:\t\t0.674414\n",
      "  validation accuracy:\t\t57.80 %\n",
      "Epoch 67 of 500 took 2.174s\n",
      "  training loss:\t\t0.652836\n",
      "  validation loss:\t\t0.673494\n",
      "  validation accuracy:\t\t57.53 %\n",
      "Epoch 68 of 500 took 2.213s\n",
      "  training loss:\t\t0.651275\n",
      "  validation loss:\t\t0.672628\n",
      "  validation accuracy:\t\t58.47 %\n",
      "Epoch 69 of 500 took 2.200s\n",
      "  training loss:\t\t0.650451\n",
      "  validation loss:\t\t0.672119\n",
      "  validation accuracy:\t\t58.40 %\n",
      "Epoch 70 of 500 took 2.183s\n",
      "  training loss:\t\t0.649388\n",
      "  validation loss:\t\t0.670936\n",
      "  validation accuracy:\t\t58.80 %\n",
      "Epoch 71 of 500 took 2.176s\n",
      "  training loss:\t\t0.648375\n",
      "  validation loss:\t\t0.670428\n",
      "  validation accuracy:\t\t59.07 %\n",
      "Epoch 72 of 500 took 2.174s\n",
      "  training loss:\t\t0.646668\n",
      "  validation loss:\t\t0.670843\n",
      "  validation accuracy:\t\t60.13 %\n",
      "Epoch 73 of 500 took 2.174s\n",
      "  training loss:\t\t0.644266\n",
      "  validation loss:\t\t0.668052\n",
      "  validation accuracy:\t\t57.80 %\n",
      "Epoch 74 of 500 took 2.176s\n",
      "  training loss:\t\t0.642069\n",
      "  validation loss:\t\t0.667185\n",
      "  validation accuracy:\t\t59.53 %\n",
      "Epoch 75 of 500 took 2.186s\n",
      "  training loss:\t\t0.641301\n",
      "  validation loss:\t\t0.666196\n",
      "  validation accuracy:\t\t59.27 %\n",
      "Epoch 76 of 500 took 2.180s\n",
      "  training loss:\t\t0.638865\n",
      "  validation loss:\t\t0.665336\n",
      "  validation accuracy:\t\t60.00 %\n",
      "Epoch 77 of 500 took 2.181s\n",
      "  training loss:\t\t0.636643\n",
      "  validation loss:\t\t0.663681\n",
      "  validation accuracy:\t\t59.20 %\n",
      "Epoch 78 of 500 took 2.174s\n",
      "  training loss:\t\t0.633453\n",
      "  validation loss:\t\t0.662910\n",
      "  validation accuracy:\t\t59.67 %\n",
      "Epoch 79 of 500 took 2.175s\n",
      "  training loss:\t\t0.632698\n",
      "  validation loss:\t\t0.661373\n",
      "  validation accuracy:\t\t60.33 %\n",
      "Epoch 80 of 500 took 2.176s\n",
      "  training loss:\t\t0.632608\n",
      "  validation loss:\t\t0.660099\n",
      "  validation accuracy:\t\t60.07 %\n",
      "Epoch 81 of 500 took 2.175s\n",
      "  training loss:\t\t0.630034\n",
      "  validation loss:\t\t0.658794\n",
      "  validation accuracy:\t\t60.67 %\n",
      "Epoch 82 of 500 took 2.181s\n",
      "  training loss:\t\t0.625240\n",
      "  validation loss:\t\t0.657765\n",
      "  validation accuracy:\t\t61.40 %\n",
      "Epoch 83 of 500 took 2.187s\n",
      "  training loss:\t\t0.623963\n",
      "  validation loss:\t\t0.655691\n",
      "  validation accuracy:\t\t61.20 %\n",
      "Epoch 84 of 500 took 2.194s\n",
      "  training loss:\t\t0.621129\n",
      "  validation loss:\t\t0.654182\n",
      "  validation accuracy:\t\t61.27 %\n",
      "Epoch 85 of 500 took 2.174s\n",
      "  training loss:\t\t0.619976\n",
      "  validation loss:\t\t0.652683\n",
      "  validation accuracy:\t\t61.60 %\n",
      "Epoch 86 of 500 took 2.175s\n",
      "  training loss:\t\t0.616413\n",
      "  validation loss:\t\t0.651237\n",
      "  validation accuracy:\t\t61.67 %\n",
      "Epoch 87 of 500 took 2.177s\n",
      "  training loss:\t\t0.614854\n",
      "  validation loss:\t\t0.649252\n",
      "  validation accuracy:\t\t62.53 %\n",
      "Epoch 88 of 500 took 2.174s\n",
      "  training loss:\t\t0.610812\n",
      "  validation loss:\t\t0.648231\n",
      "  validation accuracy:\t\t62.27 %\n",
      "Epoch 89 of 500 took 2.173s\n",
      "  training loss:\t\t0.608064\n",
      "  validation loss:\t\t0.645831\n",
      "  validation accuracy:\t\t63.33 %\n",
      "Epoch 90 of 500 took 2.176s\n",
      "  training loss:\t\t0.605736\n",
      "  validation loss:\t\t0.645223\n",
      "  validation accuracy:\t\t62.93 %\n",
      "Epoch 91 of 500 took 2.176s\n",
      "  training loss:\t\t0.602004\n",
      "  validation loss:\t\t0.642895\n",
      "  validation accuracy:\t\t63.20 %\n",
      "Epoch 92 of 500 took 2.175s\n",
      "  training loss:\t\t0.598924\n",
      "  validation loss:\t\t0.642074\n",
      "  validation accuracy:\t\t62.80 %\n",
      "Epoch 93 of 500 took 2.175s\n",
      "  training loss:\t\t0.595392\n",
      "  validation loss:\t\t0.637705\n",
      "  validation accuracy:\t\t63.67 %\n",
      "Epoch 94 of 500 took 2.182s\n",
      "  training loss:\t\t0.591733\n",
      "  validation loss:\t\t0.636391\n",
      "  validation accuracy:\t\t62.80 %\n",
      "Epoch 95 of 500 took 2.177s\n",
      "  training loss:\t\t0.588572\n",
      "  validation loss:\t\t0.634487\n",
      "  validation accuracy:\t\t64.27 %\n",
      "Epoch 96 of 500 took 2.174s\n",
      "  training loss:\t\t0.583429\n",
      "  validation loss:\t\t0.632443\n",
      "  validation accuracy:\t\t63.80 %\n",
      "Epoch 97 of 500 took 2.184s\n",
      "  training loss:\t\t0.580431\n",
      "  validation loss:\t\t0.632637\n",
      "  validation accuracy:\t\t64.07 %\n",
      "Epoch 98 of 500 took 2.188s\n",
      "  training loss:\t\t0.577443\n",
      "  validation loss:\t\t0.627510\n",
      "  validation accuracy:\t\t64.27 %\n",
      "Epoch 99 of 500 took 2.183s\n",
      "  training loss:\t\t0.573170\n",
      "  validation loss:\t\t0.625516\n",
      "  validation accuracy:\t\t63.93 %\n",
      "Epoch 100 of 500 took 2.174s\n",
      "  training loss:\t\t0.568914\n",
      "  validation loss:\t\t0.626699\n",
      "  validation accuracy:\t\t64.87 %\n",
      "Epoch 101 of 500 took 2.175s\n",
      "  training loss:\t\t0.565698\n",
      "  validation loss:\t\t0.620745\n",
      "  validation accuracy:\t\t64.60 %\n",
      "Epoch 102 of 500 took 2.175s\n",
      "  training loss:\t\t0.562189\n",
      "  validation loss:\t\t0.621321\n",
      "  validation accuracy:\t\t65.00 %\n",
      "Epoch 103 of 500 took 2.184s\n",
      "  training loss:\t\t0.560465\n",
      "  validation loss:\t\t0.616625\n",
      "  validation accuracy:\t\t65.20 %\n",
      "Epoch 104 of 500 took 2.181s\n",
      "  training loss:\t\t0.553323\n",
      "  validation loss:\t\t0.614177\n",
      "  validation accuracy:\t\t65.00 %\n",
      "Epoch 105 of 500 took 2.180s\n",
      "  training loss:\t\t0.550548\n",
      "  validation loss:\t\t0.612302\n",
      "  validation accuracy:\t\t65.20 %\n",
      "Epoch 106 of 500 took 2.232s\n",
      "  training loss:\t\t0.546911\n",
      "  validation loss:\t\t0.610336\n",
      "  validation accuracy:\t\t65.00 %\n",
      "Epoch 107 of 500 took 2.229s\n",
      "  training loss:\t\t0.541039\n",
      "  validation loss:\t\t0.608238\n",
      "  validation accuracy:\t\t65.00 %\n",
      "Epoch 108 of 500 took 2.220s\n",
      "  training loss:\t\t0.538265\n",
      "  validation loss:\t\t0.605397\n",
      "  validation accuracy:\t\t65.60 %\n",
      "Epoch 109 of 500 took 2.207s\n",
      "  training loss:\t\t0.534322\n",
      "  validation loss:\t\t0.603129\n",
      "  validation accuracy:\t\t65.67 %\n",
      "Epoch 110 of 500 took 2.182s\n",
      "  training loss:\t\t0.531336\n",
      "  validation loss:\t\t0.600835\n",
      "  validation accuracy:\t\t65.87 %\n",
      "Epoch 111 of 500 took 2.184s\n",
      "  training loss:\t\t0.526121\n",
      "  validation loss:\t\t0.600933\n",
      "  validation accuracy:\t\t66.07 %\n",
      "Epoch 112 of 500 took 2.189s\n",
      "  training loss:\t\t0.521292\n",
      "  validation loss:\t\t0.596505\n",
      "  validation accuracy:\t\t66.53 %\n",
      "Epoch 113 of 500 took 2.178s\n",
      "  training loss:\t\t0.516000\n",
      "  validation loss:\t\t0.593836\n",
      "  validation accuracy:\t\t66.53 %\n",
      "Epoch 114 of 500 took 2.192s\n",
      "  training loss:\t\t0.511900\n",
      "  validation loss:\t\t0.594619\n",
      "  validation accuracy:\t\t66.73 %\n",
      "Epoch 115 of 500 took 2.178s\n",
      "  training loss:\t\t0.513446\n",
      "  validation loss:\t\t0.590966\n",
      "  validation accuracy:\t\t67.40 %\n",
      "Epoch 116 of 500 took 2.175s\n",
      "  training loss:\t\t0.506519\n",
      "  validation loss:\t\t0.589488\n",
      "  validation accuracy:\t\t66.33 %\n",
      "Epoch 117 of 500 took 2.175s\n",
      "  training loss:\t\t0.498837\n",
      "  validation loss:\t\t0.586917\n",
      "  validation accuracy:\t\t66.53 %\n",
      "Epoch 118 of 500 took 2.176s\n",
      "  training loss:\t\t0.494144\n",
      "  validation loss:\t\t0.587487\n",
      "  validation accuracy:\t\t66.73 %\n",
      "Epoch 119 of 500 took 2.176s\n",
      "  training loss:\t\t0.492705\n",
      "  validation loss:\t\t0.583999\n",
      "  validation accuracy:\t\t67.00 %\n",
      "Epoch 120 of 500 took 2.174s\n",
      "  training loss:\t\t0.490239\n",
      "  validation loss:\t\t0.582829\n",
      "  validation accuracy:\t\t67.33 %\n",
      "Epoch 121 of 500 took 2.175s\n",
      "  training loss:\t\t0.483601\n",
      "  validation loss:\t\t0.578098\n",
      "  validation accuracy:\t\t68.00 %\n",
      "Epoch 122 of 500 took 2.188s\n",
      "  training loss:\t\t0.483353\n",
      "  validation loss:\t\t0.577451\n",
      "  validation accuracy:\t\t67.60 %\n",
      "Epoch 123 of 500 took 2.199s\n",
      "  training loss:\t\t0.475063\n",
      "  validation loss:\t\t0.575054\n",
      "  validation accuracy:\t\t67.67 %\n",
      "Epoch 124 of 500 took 2.230s\n",
      "  training loss:\t\t0.468967\n",
      "  validation loss:\t\t0.578202\n",
      "  validation accuracy:\t\t67.33 %\n",
      "Epoch 125 of 500 took 2.219s\n",
      "  training loss:\t\t0.466195\n",
      "  validation loss:\t\t0.571076\n",
      "  validation accuracy:\t\t68.53 %\n",
      "Epoch 126 of 500 took 2.223s\n",
      "  training loss:\t\t0.462063\n",
      "  validation loss:\t\t0.570873\n",
      "  validation accuracy:\t\t68.07 %\n",
      "Epoch 127 of 500 took 2.199s\n",
      "  training loss:\t\t0.459768\n",
      "  validation loss:\t\t0.567820\n",
      "  validation accuracy:\t\t68.87 %\n",
      "Epoch 128 of 500 took 2.212s\n",
      "  training loss:\t\t0.449989\n",
      "  validation loss:\t\t0.564831\n",
      "  validation accuracy:\t\t69.73 %\n",
      "Epoch 129 of 500 took 2.186s\n",
      "  training loss:\t\t0.445075\n",
      "  validation loss:\t\t0.564494\n",
      "  validation accuracy:\t\t69.07 %\n",
      "Epoch 130 of 500 took 2.211s\n",
      "  training loss:\t\t0.446530\n",
      "  validation loss:\t\t0.563046\n",
      "  validation accuracy:\t\t69.80 %\n",
      "Epoch 131 of 500 took 2.214s\n",
      "  training loss:\t\t0.440885\n",
      "  validation loss:\t\t0.561051\n",
      "  validation accuracy:\t\t70.20 %\n",
      "Epoch 132 of 500 took 2.193s\n",
      "  training loss:\t\t0.435627\n",
      "  validation loss:\t\t0.558987\n",
      "  validation accuracy:\t\t70.13 %\n",
      "Epoch 133 of 500 took 2.206s\n",
      "  training loss:\t\t0.431453\n",
      "  validation loss:\t\t0.559216\n",
      "  validation accuracy:\t\t70.53 %\n",
      "Epoch 134 of 500 took 2.192s\n",
      "  training loss:\t\t0.430285\n",
      "  validation loss:\t\t0.557041\n",
      "  validation accuracy:\t\t69.87 %\n",
      "Epoch 135 of 500 took 2.182s\n",
      "  training loss:\t\t0.425549\n",
      "  validation loss:\t\t0.556715\n",
      "  validation accuracy:\t\t69.80 %\n",
      "Epoch 136 of 500 took 2.175s\n",
      "  training loss:\t\t0.421181\n",
      "  validation loss:\t\t0.560204\n",
      "  validation accuracy:\t\t69.80 %\n",
      "Epoch 137 of 500 took 2.176s\n",
      "  training loss:\t\t0.415581\n",
      "  validation loss:\t\t0.553323\n",
      "  validation accuracy:\t\t69.87 %\n",
      "Epoch 138 of 500 took 2.175s\n",
      "  training loss:\t\t0.411490\n",
      "  validation loss:\t\t0.552789\n",
      "  validation accuracy:\t\t70.47 %\n",
      "Epoch 139 of 500 took 2.195s\n",
      "  training loss:\t\t0.411413\n",
      "  validation loss:\t\t0.549331\n",
      "  validation accuracy:\t\t70.40 %\n",
      "Epoch 140 of 500 took 2.198s\n",
      "  training loss:\t\t0.405997\n",
      "  validation loss:\t\t0.550283\n",
      "  validation accuracy:\t\t70.93 %\n",
      "Epoch 141 of 500 took 2.183s\n",
      "  training loss:\t\t0.403626\n",
      "  validation loss:\t\t0.556082\n",
      "  validation accuracy:\t\t69.60 %\n",
      "Epoch 142 of 500 took 2.176s\n",
      "  training loss:\t\t0.395971\n",
      "  validation loss:\t\t0.547494\n",
      "  validation accuracy:\t\t70.33 %\n",
      "Epoch 143 of 500 took 2.175s\n",
      "  training loss:\t\t0.390420\n",
      "  validation loss:\t\t0.549508\n",
      "  validation accuracy:\t\t70.93 %\n",
      "Epoch 144 of 500 took 2.176s\n",
      "  training loss:\t\t0.389150\n",
      "  validation loss:\t\t0.551001\n",
      "  validation accuracy:\t\t69.93 %\n",
      "Epoch 145 of 500 took 2.175s\n",
      "  training loss:\t\t0.381645\n",
      "  validation loss:\t\t0.548715\n",
      "  validation accuracy:\t\t70.47 %\n",
      "Epoch 146 of 500 took 2.176s\n",
      "  training loss:\t\t0.380811\n",
      "  validation loss:\t\t0.546746\n",
      "  validation accuracy:\t\t70.87 %\n",
      "Epoch 147 of 500 took 2.173s\n",
      "  training loss:\t\t0.375389\n",
      "  validation loss:\t\t0.545528\n",
      "  validation accuracy:\t\t70.60 %\n",
      "Epoch 148 of 500 took 2.175s\n",
      "  training loss:\t\t0.369261\n",
      "  validation loss:\t\t0.545910\n",
      "  validation accuracy:\t\t70.07 %\n",
      "Epoch 149 of 500 took 2.182s\n",
      "  training loss:\t\t0.369019\n",
      "  validation loss:\t\t0.541842\n",
      "  validation accuracy:\t\t70.67 %\n",
      "Epoch 150 of 500 took 2.189s\n",
      "  training loss:\t\t0.366015\n",
      "  validation loss:\t\t0.543299\n",
      "  validation accuracy:\t\t70.20 %\n",
      "Epoch 151 of 500 took 2.180s\n",
      "  training loss:\t\t0.356041\n",
      "  validation loss:\t\t0.542527\n",
      "  validation accuracy:\t\t71.13 %\n",
      "Epoch 152 of 500 took 2.194s\n",
      "  training loss:\t\t0.359776\n",
      "  validation loss:\t\t0.538698\n",
      "  validation accuracy:\t\t71.40 %\n",
      "Epoch 153 of 500 took 2.199s\n",
      "  training loss:\t\t0.355463\n",
      "  validation loss:\t\t0.538524\n",
      "  validation accuracy:\t\t70.67 %\n",
      "Epoch 154 of 500 took 2.210s\n",
      "  training loss:\t\t0.349434\n",
      "  validation loss:\t\t0.537738\n",
      "  validation accuracy:\t\t71.07 %\n",
      "Epoch 155 of 500 took 2.208s\n",
      "  training loss:\t\t0.342470\n",
      "  validation loss:\t\t0.540115\n",
      "  validation accuracy:\t\t71.67 %\n",
      "Epoch 156 of 500 took 2.197s\n",
      "  training loss:\t\t0.337931\n",
      "  validation loss:\t\t0.537206\n",
      "  validation accuracy:\t\t71.00 %\n",
      "Epoch 157 of 500 took 2.179s\n",
      "  training loss:\t\t0.337833\n",
      "  validation loss:\t\t0.536980\n",
      "  validation accuracy:\t\t70.93 %\n",
      "Epoch 158 of 500 took 2.175s\n",
      "  training loss:\t\t0.324383\n",
      "  validation loss:\t\t0.538384\n",
      "  validation accuracy:\t\t71.53 %\n",
      "Epoch 159 of 500 took 2.181s\n",
      "  training loss:\t\t0.329022\n",
      "  validation loss:\t\t0.536669\n",
      "  validation accuracy:\t\t71.13 %\n",
      "Epoch 160 of 500 took 2.188s\n",
      "  training loss:\t\t0.326115\n",
      "  validation loss:\t\t0.537979\n",
      "  validation accuracy:\t\t72.13 %\n",
      "Epoch 161 of 500 took 2.201s\n",
      "  training loss:\t\t0.320627\n",
      "  validation loss:\t\t0.536838\n",
      "  validation accuracy:\t\t72.13 %\n",
      "Epoch 162 of 500 took 2.207s\n",
      "  training loss:\t\t0.319006\n",
      "  validation loss:\t\t0.542042\n",
      "  validation accuracy:\t\t72.00 %\n",
      "Epoch 163 of 500 took 2.196s\n",
      "  training loss:\t\t0.311128\n",
      "  validation loss:\t\t0.538714\n",
      "  validation accuracy:\t\t70.93 %\n",
      "Epoch 164 of 500 took 2.180s\n",
      "  training loss:\t\t0.308745\n",
      "  validation loss:\t\t0.535779\n",
      "  validation accuracy:\t\t71.80 %\n",
      "Epoch 165 of 500 took 2.202s\n",
      "  training loss:\t\t0.310334\n",
      "  validation loss:\t\t0.533960\n",
      "  validation accuracy:\t\t71.53 %\n",
      "Epoch 166 of 500 took 2.191s\n",
      "  training loss:\t\t0.305745\n",
      "  validation loss:\t\t0.536252\n",
      "  validation accuracy:\t\t71.47 %\n",
      "Epoch 167 of 500 took 2.185s\n",
      "  training loss:\t\t0.293850\n",
      "  validation loss:\t\t0.537869\n",
      "  validation accuracy:\t\t71.53 %\n",
      "Epoch 168 of 500 took 2.203s\n",
      "  training loss:\t\t0.295654\n",
      "  validation loss:\t\t0.534797\n",
      "  validation accuracy:\t\t71.47 %\n",
      "Epoch 169 of 500 took 2.182s\n",
      "  training loss:\t\t0.294220\n",
      "  validation loss:\t\t0.539981\n",
      "  validation accuracy:\t\t72.13 %\n",
      "Epoch 170 of 500 took 2.175s\n",
      "  training loss:\t\t0.286585\n",
      "  validation loss:\t\t0.539204\n",
      "  validation accuracy:\t\t71.93 %\n",
      "Epoch 171 of 500 took 2.214s\n",
      "  training loss:\t\t0.287247\n",
      "  validation loss:\t\t0.537167\n",
      "  validation accuracy:\t\t71.80 %\n",
      "Epoch 172 of 500 took 2.183s\n",
      "  training loss:\t\t0.278620\n",
      "  validation loss:\t\t0.536770\n",
      "  validation accuracy:\t\t72.87 %\n",
      "Epoch 173 of 500 took 2.181s\n",
      "  training loss:\t\t0.276276\n",
      "  validation loss:\t\t0.536475\n",
      "  validation accuracy:\t\t71.47 %\n",
      "Epoch 174 of 500 took 2.177s\n",
      "  training loss:\t\t0.278095\n",
      "  validation loss:\t\t0.538921\n",
      "  validation accuracy:\t\t72.13 %\n",
      "Epoch 175 of 500 took 2.176s\n",
      "  training loss:\t\t0.274770\n",
      "  validation loss:\t\t0.534607\n",
      "  validation accuracy:\t\t72.00 %\n",
      "Epoch 176 of 500 took 2.174s\n",
      "  training loss:\t\t0.268317\n",
      "  validation loss:\t\t0.543377\n",
      "  validation accuracy:\t\t71.00 %\n",
      "Epoch 177 of 500 took 2.176s\n",
      "  training loss:\t\t0.266847\n",
      "  validation loss:\t\t0.539649\n",
      "  validation accuracy:\t\t72.20 %\n",
      "Epoch 178 of 500 took 2.192s\n",
      "  training loss:\t\t0.263772\n",
      "  validation loss:\t\t0.541143\n",
      "  validation accuracy:\t\t71.20 %\n",
      "Epoch 179 of 500 took 2.193s\n",
      "  training loss:\t\t0.256122\n",
      "  validation loss:\t\t0.541963\n",
      "  validation accuracy:\t\t71.33 %\n",
      "Epoch 180 of 500 took 2.184s\n",
      "  training loss:\t\t0.251320\n",
      "  validation loss:\t\t0.544081\n",
      "  validation accuracy:\t\t71.13 %\n",
      "Epoch 181 of 500 took 2.174s\n",
      "  training loss:\t\t0.247955\n",
      "  validation loss:\t\t0.540026\n",
      "  validation accuracy:\t\t72.27 %\n",
      "Epoch 182 of 500 took 2.174s\n",
      "  training loss:\t\t0.247625\n",
      "  validation loss:\t\t0.550772\n",
      "  validation accuracy:\t\t72.40 %\n",
      "Epoch 183 of 500 took 2.202s\n",
      "  training loss:\t\t0.245594\n",
      "  validation loss:\t\t0.540697\n",
      "  validation accuracy:\t\t72.27 %\n",
      "Epoch 184 of 500 took 2.208s\n",
      "  training loss:\t\t0.240911\n",
      "  validation loss:\t\t0.543035\n",
      "  validation accuracy:\t\t72.40 %\n",
      "Epoch 185 of 500 took 2.150s\n",
      "  training loss:\t\t0.235980\n",
      "  validation loss:\t\t0.547698\n",
      "  validation accuracy:\t\t72.27 %\n",
      "Epoch 186 of 500 took 2.179s\n",
      "  training loss:\t\t0.238654\n",
      "  validation loss:\t\t0.544273\n",
      "  validation accuracy:\t\t72.53 %\n",
      "Epoch 187 of 500 took 2.192s\n",
      "  training loss:\t\t0.231224\n",
      "  validation loss:\t\t0.550955\n",
      "  validation accuracy:\t\t71.40 %\n",
      "Epoch 188 of 500 took 2.189s\n",
      "  training loss:\t\t0.227449\n",
      "  validation loss:\t\t0.547976\n",
      "  validation accuracy:\t\t72.27 %\n",
      "Epoch 189 of 500 took 2.191s\n",
      "  training loss:\t\t0.232387\n",
      "  validation loss:\t\t0.544393\n",
      "  validation accuracy:\t\t72.40 %\n",
      "Epoch 190 of 500 took 2.132s\n",
      "  training loss:\t\t0.225592\n",
      "  validation loss:\t\t0.546827\n",
      "  validation accuracy:\t\t72.40 %\n",
      "Epoch 191 of 500 took 2.210s\n",
      "  training loss:\t\t0.217974\n",
      "  validation loss:\t\t0.560178\n",
      "  validation accuracy:\t\t72.20 %\n",
      "Epoch 192 of 500 took 2.154s\n",
      "  training loss:\t\t0.218952\n",
      "  validation loss:\t\t0.547766\n",
      "  validation accuracy:\t\t72.60 %\n",
      "Epoch 193 of 500 took 2.199s\n",
      "  training loss:\t\t0.215377\n",
      "  validation loss:\t\t0.555419\n",
      "  validation accuracy:\t\t71.33 %\n",
      "Epoch 194 of 500 took 2.258s\n",
      "  training loss:\t\t0.212878\n",
      "  validation loss:\t\t0.559523\n",
      "  validation accuracy:\t\t71.53 %\n",
      "Epoch 195 of 500 took 2.247s\n",
      "  training loss:\t\t0.209777\n",
      "  validation loss:\t\t0.552216\n",
      "  validation accuracy:\t\t71.80 %\n",
      "Epoch 196 of 500 took 2.236s\n",
      "  training loss:\t\t0.210583\n",
      "  validation loss:\t\t0.555602\n",
      "  validation accuracy:\t\t71.93 %\n",
      "Epoch 197 of 500 took 2.129s\n",
      "  training loss:\t\t0.203532\n",
      "  validation loss:\t\t0.561038\n",
      "  validation accuracy:\t\t71.20 %\n",
      "Epoch 198 of 500 took 2.150s\n",
      "  training loss:\t\t0.214563\n",
      "  validation loss:\t\t0.559224\n",
      "  validation accuracy:\t\t72.07 %\n",
      "Epoch 199 of 500 took 2.127s\n",
      "  training loss:\t\t0.202819\n",
      "  validation loss:\t\t0.554632\n",
      "  validation accuracy:\t\t72.53 %\n",
      "Epoch 200 of 500 took 2.146s\n",
      "  training loss:\t\t0.192037\n",
      "  validation loss:\t\t0.556016\n",
      "  validation accuracy:\t\t72.47 %\n",
      "Epoch 201 of 500 took 2.101s\n",
      "  training loss:\t\t0.196183\n",
      "  validation loss:\t\t0.558701\n",
      "  validation accuracy:\t\t72.47 %\n",
      "Epoch 202 of 500 took 2.116s\n",
      "  training loss:\t\t0.191994\n",
      "  validation loss:\t\t0.563551\n",
      "  validation accuracy:\t\t72.13 %\n",
      "Epoch 203 of 500 took 2.119s\n",
      "  training loss:\t\t0.194584\n",
      "  validation loss:\t\t0.557516\n",
      "  validation accuracy:\t\t72.67 %\n",
      "Epoch 204 of 500 took 2.100s\n",
      "  training loss:\t\t0.190704\n",
      "  validation loss:\t\t0.567537\n",
      "  validation accuracy:\t\t72.27 %\n",
      "Epoch 205 of 500 took 2.148s\n",
      "  training loss:\t\t0.186156\n",
      "  validation loss:\t\t0.561932\n",
      "  validation accuracy:\t\t72.60 %\n",
      "Epoch 206 of 500 took 2.110s\n",
      "  training loss:\t\t0.188253\n",
      "  validation loss:\t\t0.571187\n",
      "  validation accuracy:\t\t71.33 %\n",
      "Epoch 207 of 500 took 2.101s\n",
      "  training loss:\t\t0.177878\n",
      "  validation loss:\t\t0.560170\n",
      "  validation accuracy:\t\t72.47 %\n",
      "Epoch 208 of 500 took 2.105s\n",
      "  training loss:\t\t0.185519\n",
      "  validation loss:\t\t0.570247\n",
      "  validation accuracy:\t\t71.60 %\n",
      "Epoch 209 of 500 took 2.130s\n",
      "  training loss:\t\t0.181231\n",
      "  validation loss:\t\t0.568027\n",
      "  validation accuracy:\t\t72.00 %\n",
      "Epoch 210 of 500 took 2.101s\n",
      "  training loss:\t\t0.173704\n",
      "  validation loss:\t\t0.568951\n",
      "  validation accuracy:\t\t72.73 %\n",
      "Epoch 211 of 500 took 2.125s\n",
      "  training loss:\t\t0.175673\n",
      "  validation loss:\t\t0.575172\n",
      "  validation accuracy:\t\t71.27 %\n",
      "Epoch 212 of 500 took 2.124s\n",
      "  training loss:\t\t0.178673\n",
      "  validation loss:\t\t0.578337\n",
      "  validation accuracy:\t\t71.33 %\n",
      "Epoch 213 of 500 took 2.147s\n",
      "  training loss:\t\t0.171546\n",
      "  validation loss:\t\t0.569089\n",
      "  validation accuracy:\t\t72.13 %\n",
      "Epoch 214 of 500 took 2.151s\n",
      "  training loss:\t\t0.167096\n",
      "  validation loss:\t\t0.573935\n",
      "  validation accuracy:\t\t72.47 %\n",
      "Epoch 215 of 500 took 2.133s\n",
      "  training loss:\t\t0.166424\n",
      "  validation loss:\t\t0.575311\n",
      "  validation accuracy:\t\t71.80 %\n",
      "Epoch 216 of 500 took 2.101s\n",
      "  training loss:\t\t0.163960\n",
      "  validation loss:\t\t0.576817\n",
      "  validation accuracy:\t\t72.40 %\n",
      "Epoch 217 of 500 took 2.101s\n",
      "  training loss:\t\t0.159925\n",
      "  validation loss:\t\t0.578579\n",
      "  validation accuracy:\t\t72.60 %\n",
      "Epoch 218 of 500 took 2.101s\n",
      "  training loss:\t\t0.168093\n",
      "  validation loss:\t\t0.574377\n",
      "  validation accuracy:\t\t72.47 %\n",
      "Epoch 219 of 500 took 2.103s\n",
      "  training loss:\t\t0.164516\n",
      "  validation loss:\t\t0.578851\n",
      "  validation accuracy:\t\t72.73 %\n",
      "Epoch 220 of 500 took 2.099s\n",
      "  training loss:\t\t0.160194\n",
      "  validation loss:\t\t0.578789\n",
      "  validation accuracy:\t\t72.07 %\n",
      "Epoch 221 of 500 took 2.100s\n",
      "  training loss:\t\t0.157728\n",
      "  validation loss:\t\t0.581506\n",
      "  validation accuracy:\t\t72.33 %\n",
      "Epoch 222 of 500 took 2.100s\n",
      "  training loss:\t\t0.153957\n",
      "  validation loss:\t\t0.583788\n",
      "  validation accuracy:\t\t72.00 %\n",
      "Epoch 223 of 500 took 2.100s\n",
      "  training loss:\t\t0.150241\n",
      "  validation loss:\t\t0.585083\n",
      "  validation accuracy:\t\t72.00 %\n",
      "Epoch 224 of 500 took 2.146s\n",
      "  training loss:\t\t0.153300\n",
      "  validation loss:\t\t0.581963\n",
      "  validation accuracy:\t\t72.27 %\n",
      "Epoch 225 of 500 took 2.132s\n",
      "  training loss:\t\t0.148051\n",
      "  validation loss:\t\t0.596978\n",
      "  validation accuracy:\t\t71.13 %\n",
      "Epoch 226 of 500 took 2.122s\n",
      "  training loss:\t\t0.150141\n",
      "  validation loss:\t\t0.593331\n",
      "  validation accuracy:\t\t71.93 %\n",
      "Epoch 227 of 500 took 2.117s\n",
      "  training loss:\t\t0.144031\n",
      "  validation loss:\t\t0.588431\n",
      "  validation accuracy:\t\t72.20 %\n",
      "Epoch 228 of 500 took 2.100s\n",
      "  training loss:\t\t0.144942\n",
      "  validation loss:\t\t0.588701\n",
      "  validation accuracy:\t\t72.13 %\n",
      "Epoch 229 of 500 took 2.153s\n",
      "  training loss:\t\t0.143241\n",
      "  validation loss:\t\t0.596795\n",
      "  validation accuracy:\t\t72.27 %\n",
      "Epoch 230 of 500 took 2.249s\n",
      "  training loss:\t\t0.139205\n",
      "  validation loss:\t\t0.599952\n",
      "  validation accuracy:\t\t71.53 %\n",
      "Epoch 231 of 500 took 2.108s\n",
      "  training loss:\t\t0.139668\n",
      "  validation loss:\t\t0.595682\n",
      "  validation accuracy:\t\t71.80 %\n",
      "Epoch 232 of 500 took 2.104s\n",
      "  training loss:\t\t0.140329\n",
      "  validation loss:\t\t0.598267\n",
      "  validation accuracy:\t\t72.53 %\n",
      "Epoch 233 of 500 took 2.101s\n",
      "  training loss:\t\t0.140102\n",
      "  validation loss:\t\t0.598004\n",
      "  validation accuracy:\t\t72.07 %\n",
      "Epoch 234 of 500 took 2.102s\n",
      "  training loss:\t\t0.136932\n",
      "  validation loss:\t\t0.605017\n",
      "  validation accuracy:\t\t72.27 %\n",
      "Epoch 235 of 500 took 2.102s\n",
      "  training loss:\t\t0.128272\n",
      "  validation loss:\t\t0.600315\n",
      "  validation accuracy:\t\t72.27 %\n",
      "Epoch 236 of 500 took 2.105s\n",
      "  training loss:\t\t0.135352\n",
      "  validation loss:\t\t0.601889\n",
      "  validation accuracy:\t\t71.87 %\n",
      "Epoch 237 of 500 took 2.123s\n",
      "  training loss:\t\t0.133558\n",
      "  validation loss:\t\t0.601394\n",
      "  validation accuracy:\t\t72.33 %\n",
      "Epoch 238 of 500 took 2.101s\n",
      "  training loss:\t\t0.127809\n",
      "  validation loss:\t\t0.609193\n",
      "  validation accuracy:\t\t72.33 %\n",
      "Epoch 239 of 500 took 2.100s\n",
      "  training loss:\t\t0.127742\n",
      "  validation loss:\t\t0.616404\n",
      "  validation accuracy:\t\t71.53 %\n",
      "Epoch 240 of 500 took 2.101s\n",
      "  training loss:\t\t0.126151\n",
      "  validation loss:\t\t0.610295\n",
      "  validation accuracy:\t\t71.80 %\n",
      "Epoch 241 of 500 took 2.100s\n",
      "  training loss:\t\t0.121071\n",
      "  validation loss:\t\t0.610329\n",
      "  validation accuracy:\t\t72.27 %\n",
      "Epoch 242 of 500 took 2.101s\n",
      "  training loss:\t\t0.128206\n",
      "  validation loss:\t\t0.612744\n",
      "  validation accuracy:\t\t71.87 %\n",
      "Epoch 243 of 500 took 2.100s\n",
      "  training loss:\t\t0.125876\n",
      "  validation loss:\t\t0.625035\n",
      "  validation accuracy:\t\t71.40 %\n",
      "Epoch 244 of 500 took 2.101s\n",
      "  training loss:\t\t0.126261\n",
      "  validation loss:\t\t0.611189\n",
      "  validation accuracy:\t\t72.00 %\n",
      "Epoch 245 of 500 took 2.101s\n",
      "  training loss:\t\t0.122254\n",
      "  validation loss:\t\t0.614818\n",
      "  validation accuracy:\t\t71.73 %\n",
      "Epoch 246 of 500 took 2.101s\n",
      "  training loss:\t\t0.121542\n",
      "  validation loss:\t\t0.616167\n",
      "  validation accuracy:\t\t71.87 %\n",
      "Epoch 247 of 500 took 2.100s\n",
      "  training loss:\t\t0.118577\n",
      "  validation loss:\t\t0.626618\n",
      "  validation accuracy:\t\t71.40 %\n",
      "Epoch 248 of 500 took 2.100s\n",
      "  training loss:\t\t0.118321\n",
      "  validation loss:\t\t0.616019\n",
      "  validation accuracy:\t\t71.87 %\n",
      "Epoch 249 of 500 took 2.100s\n",
      "  training loss:\t\t0.118749\n",
      "  validation loss:\t\t0.618700\n",
      "  validation accuracy:\t\t71.73 %\n",
      "Epoch 250 of 500 took 2.099s\n",
      "  training loss:\t\t0.117734\n",
      "  validation loss:\t\t0.623067\n",
      "  validation accuracy:\t\t71.67 %\n",
      "Epoch 251 of 500 took 2.101s\n",
      "  training loss:\t\t0.117097\n",
      "  validation loss:\t\t0.630670\n",
      "  validation accuracy:\t\t71.07 %\n",
      "Epoch 252 of 500 took 2.099s\n",
      "  training loss:\t\t0.115228\n",
      "  validation loss:\t\t0.623573\n",
      "  validation accuracy:\t\t72.13 %\n",
      "Epoch 253 of 500 took 2.102s\n",
      "  training loss:\t\t0.110227\n",
      "  validation loss:\t\t0.620476\n",
      "  validation accuracy:\t\t72.47 %\n",
      "Epoch 254 of 500 took 2.100s\n",
      "  training loss:\t\t0.114159\n",
      "  validation loss:\t\t0.637050\n",
      "  validation accuracy:\t\t71.53 %\n",
      "Epoch 255 of 500 took 2.100s\n",
      "  training loss:\t\t0.115208\n",
      "  validation loss:\t\t0.627957\n",
      "  validation accuracy:\t\t71.47 %\n",
      "Epoch 256 of 500 took 2.100s\n",
      "  training loss:\t\t0.110251\n",
      "  validation loss:\t\t0.635187\n",
      "  validation accuracy:\t\t71.53 %\n",
      "Epoch 257 of 500 took 2.100s\n",
      "  training loss:\t\t0.108343\n",
      "  validation loss:\t\t0.627924\n",
      "  validation accuracy:\t\t72.40 %\n",
      "Epoch 258 of 500 took 2.101s\n",
      "  training loss:\t\t0.108586\n",
      "  validation loss:\t\t0.627580\n",
      "  validation accuracy:\t\t72.07 %\n",
      "Epoch 259 of 500 took 2.099s\n",
      "  training loss:\t\t0.108395\n",
      "  validation loss:\t\t0.640796\n",
      "  validation accuracy:\t\t71.87 %\n",
      "Epoch 260 of 500 took 2.099s\n",
      "  training loss:\t\t0.109273\n",
      "  validation loss:\t\t0.635431\n",
      "  validation accuracy:\t\t71.47 %\n",
      "Epoch 261 of 500 took 2.101s\n",
      "  training loss:\t\t0.105044\n",
      "  validation loss:\t\t0.636255\n",
      "  validation accuracy:\t\t72.47 %\n",
      "Epoch 262 of 500 took 2.101s\n",
      "  training loss:\t\t0.107034\n",
      "  validation loss:\t\t0.636204\n",
      "  validation accuracy:\t\t72.20 %\n",
      "Epoch 263 of 500 took 2.101s\n",
      "  training loss:\t\t0.101887\n",
      "  validation loss:\t\t0.643415\n",
      "  validation accuracy:\t\t71.73 %\n",
      "Epoch 264 of 500 took 2.100s\n",
      "  training loss:\t\t0.107134\n",
      "  validation loss:\t\t0.644311\n",
      "  validation accuracy:\t\t71.67 %\n",
      "Epoch 265 of 500 took 2.100s\n",
      "  training loss:\t\t0.103712\n",
      "  validation loss:\t\t0.654417\n",
      "  validation accuracy:\t\t71.20 %\n",
      "Epoch 266 of 500 took 2.100s\n",
      "  training loss:\t\t0.102071\n",
      "  validation loss:\t\t0.644205\n",
      "  validation accuracy:\t\t71.80 %\n",
      "Epoch 267 of 500 took 2.101s\n",
      "  training loss:\t\t0.100033\n",
      "  validation loss:\t\t0.652249\n",
      "  validation accuracy:\t\t71.47 %\n",
      "Epoch 268 of 500 took 2.099s\n",
      "  training loss:\t\t0.103542\n",
      "  validation loss:\t\t0.644978\n",
      "  validation accuracy:\t\t71.73 %\n",
      "Epoch 269 of 500 took 2.100s\n",
      "  training loss:\t\t0.100495\n",
      "  validation loss:\t\t0.663952\n",
      "  validation accuracy:\t\t71.47 %\n",
      "Epoch 270 of 500 took 2.101s\n",
      "  training loss:\t\t0.098809\n",
      "  validation loss:\t\t0.657235\n",
      "  validation accuracy:\t\t71.93 %\n",
      "Epoch 271 of 500 took 2.100s\n",
      "  training loss:\t\t0.100012\n",
      "  validation loss:\t\t0.656714\n",
      "  validation accuracy:\t\t71.73 %\n",
      "Epoch 272 of 500 took 2.099s\n",
      "  training loss:\t\t0.092767\n",
      "  validation loss:\t\t0.658251\n",
      "  validation accuracy:\t\t71.27 %\n",
      "Epoch 273 of 500 took 2.100s\n",
      "  training loss:\t\t0.098383\n",
      "  validation loss:\t\t0.654376\n",
      "  validation accuracy:\t\t71.47 %\n",
      "Epoch 274 of 500 took 2.100s\n",
      "  training loss:\t\t0.096354\n",
      "  validation loss:\t\t0.656512\n",
      "  validation accuracy:\t\t71.53 %\n",
      "Epoch 275 of 500 took 2.100s\n",
      "  training loss:\t\t0.097473\n",
      "  validation loss:\t\t0.682318\n",
      "  validation accuracy:\t\t71.60 %\n",
      "Epoch 276 of 500 took 2.101s\n",
      "  training loss:\t\t0.092726\n",
      "  validation loss:\t\t0.678139\n",
      "  validation accuracy:\t\t71.47 %\n",
      "Epoch 277 of 500 took 2.150s\n",
      "  training loss:\t\t0.097358\n",
      "  validation loss:\t\t0.659888\n",
      "  validation accuracy:\t\t71.67 %\n",
      "Epoch 278 of 500 took 2.232s\n",
      "  training loss:\t\t0.096192\n",
      "  validation loss:\t\t0.666412\n",
      "  validation accuracy:\t\t71.53 %\n",
      "Epoch 279 of 500 took 2.119s\n",
      "  training loss:\t\t0.091025\n",
      "  validation loss:\t\t0.667678\n",
      "  validation accuracy:\t\t71.47 %\n",
      "Epoch 280 of 500 took 2.112s\n",
      "  training loss:\t\t0.093421\n",
      "  validation loss:\t\t0.672249\n",
      "  validation accuracy:\t\t71.33 %\n",
      "Epoch 281 of 500 took 2.135s\n",
      "  training loss:\t\t0.096121\n",
      "  validation loss:\t\t0.673754\n",
      "  validation accuracy:\t\t71.73 %\n",
      "Epoch 282 of 500 took 2.100s\n",
      "  training loss:\t\t0.093723\n",
      "  validation loss:\t\t0.674232\n",
      "  validation accuracy:\t\t71.47 %\n",
      "Epoch 283 of 500 took 2.100s\n",
      "  training loss:\t\t0.091102\n",
      "  validation loss:\t\t0.670395\n",
      "  validation accuracy:\t\t72.07 %\n",
      "Epoch 284 of 500 took 2.100s\n",
      "  training loss:\t\t0.089676\n",
      "  validation loss:\t\t0.686724\n",
      "  validation accuracy:\t\t71.07 %\n",
      "Epoch 285 of 500 took 2.128s\n",
      "  training loss:\t\t0.091936\n",
      "  validation loss:\t\t0.684771\n",
      "  validation accuracy:\t\t71.47 %\n",
      "Epoch 286 of 500 took 2.138s\n",
      "  training loss:\t\t0.093566\n",
      "  validation loss:\t\t0.674295\n",
      "  validation accuracy:\t\t71.67 %\n",
      "Epoch 287 of 500 took 2.099s\n",
      "  training loss:\t\t0.088999\n",
      "  validation loss:\t\t0.678446\n",
      "  validation accuracy:\t\t71.73 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-43ba018e1687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"val freq\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-f9770c3b306b>\u001b[0m in \u001b[0;36mtrain_cnn\u001b[0;34m(X_train, y_train, X_val, y_val, X_test, num_epochs)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mtrain_err\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mtrain_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, val_index in skf.split(data, label):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", val_index)\n",
    "    data_train, data_val = data[train_index], data[val_index]\n",
    "    label_train, label_val = label[train_index], label[val_index]\n",
    "    \n",
    "    freq_train = itemfreq(label_train)\n",
    "    print \"train freq\", freq_train[:,1]\n",
    "    freq_val = itemfreq(label_val)\n",
    "    print \"val freq\", freq_val[:,1]\n",
    "    \n",
    "    train_cnn(data_train, label_train, data_val, label_val, data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
