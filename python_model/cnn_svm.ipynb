{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5105 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1080 (0000:01:00.0)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "from scipy.stats import itemfreq\n",
    "import random\n",
    "import os.path\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import visualize\n",
    "from nolearn.lasagne import BatchIterator\n",
    "from nolearn.lasagne import TrainSplit\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "\n",
    "# import user defined load_data to build input data\n",
    "from load_data import Data\n",
    "from utils import save_network\n",
    "\n",
    "# Enter your own file path here, in the path it should contain two \n",
    "# directories, data and word2vec\n",
    "FILE_PATH = '/home/sam/Hhd/twitter_sentiment/'\n",
    "# FILE_PATH = '/home/sam/Data/twitter_sentiment/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Airline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading csv: Airline-Sentiment-2-w-AA.csv ...\n",
      "Note: pre-process changes the dataframe inplace.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>What  said</td>\n",
       "      <td>[said]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>plus youve added commercials to the experienc...</td>\n",
       "      <td>[plus, youve, added, commercials, experience, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I didnt today Must mean I need to take anothe...</td>\n",
       "      <td>[didnt, today, must, mean, need, take, another...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>its really aggressive to blast obnoxious ente...</td>\n",
       "      <td>[really, aggressive, blast, obnoxious, enterta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>and its a really big bad thing about it</td>\n",
       "      <td>[really, big, bad, thing]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0           neutral                                         What  said   \n",
       "1          positive   plus youve added commercials to the experienc...   \n",
       "2           neutral   I didnt today Must mean I need to take anothe...   \n",
       "3          negative   its really aggressive to blast obnoxious ente...   \n",
       "4          negative            and its a really big bad thing about it   \n",
       "\n",
       "                                           tokenized  \n",
       "0                                             [said]  \n",
       "1  [plus, youve, added, commercials, experience, ...  \n",
       "2  [didnt, today, must, mean, need, take, another...  \n",
       "3  [really, aggressive, blast, obnoxious, enterta...  \n",
       "4                          [really, big, bad, thing]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_data = Data('Airline-Sentiment-2-w-AA.csv', FILE_PATH)\n",
    "airline_df = airline_data.csv_df(['airline_sentiment', 'text']) # load data\n",
    "airline_data.pre_process(airline_df) # pre-process data\n",
    "# drop neutral\n",
    "# airline_df = airline_data.drop_value(airline_df, 'airline_sentiment', 'neutral')\n",
    "airline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "Done converting categorical to numeric, this changes df.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What  said</td>\n",
       "      <td>[said]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus youve added commercials to the experienc...</td>\n",
       "      <td>[plus, youve, added, commercials, experience, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I didnt today Must mean I need to take anothe...</td>\n",
       "      <td>[didnt, today, must, mean, need, take, another...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>its really aggressive to blast obnoxious ente...</td>\n",
       "      <td>[really, aggressive, blast, obnoxious, enterta...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and its a really big bad thing about it</td>\n",
       "      <td>[really, big, bad, thing]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                                         What  said   \n",
       "1   plus youve added commercials to the experienc...   \n",
       "2   I didnt today Must mean I need to take anothe...   \n",
       "3   its really aggressive to blast obnoxious ente...   \n",
       "4            and its a really big bad thing about it   \n",
       "\n",
       "                                           tokenized  class  \n",
       "0                                             [said]      2  \n",
       "1  [plus, youve, added, commercials, experience, ...      1  \n",
       "2  [didnt, today, must, mean, need, take, another...      2  \n",
       "3  [really, aggressive, blast, obnoxious, enterta...      3  \n",
       "4                          [really, big, bad, thing]      3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert categorical value to int class\n",
    "# class_label = {'positive': 1, 'negative': 2}\n",
    "class_label = {'positive': 1, 'neutral': 2, 'negative': 3}\n",
    "\n",
    "airline_df = airline_data.cat2num(airline_df, 'airline_sentiment', class_label, 'class')\n",
    "airline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    9178\n",
       "2    3099\n",
       "1    2363\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets take a look of the \n",
    "airline_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    3099\n",
       "2    3099\n",
       "1    2363\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comment out if do not want class balance\n",
    "airline_df = airline_data.balance_class(airline_df)\n",
    "# and check again\n",
    "airline_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What  said</td>\n",
       "      <td>[said]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus youve added commercials to the experienc...</td>\n",
       "      <td>[plus, youve, added, commercials, experience, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I didnt today Must mean I need to take anothe...</td>\n",
       "      <td>[didnt, today, must, mean, need, take, another...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seriously would pay  a flight for seats that ...</td>\n",
       "      <td>[seriously, would, pay, flight, seats, didnt, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes nearly every time I fly VX this ear worm ...</td>\n",
       "      <td>[yes, nearly, every, time, fly, vx, ear, worm,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                                         What  said   \n",
       "1   plus youve added commercials to the experienc...   \n",
       "2   I didnt today Must mean I need to take anothe...   \n",
       "3   seriously would pay  a flight for seats that ...   \n",
       "4   yes nearly every time I fly VX this ear worm ...   \n",
       "\n",
       "                                           tokenized  class  \n",
       "0                                             [said]      2  \n",
       "1  [plus, youve, added, commercials, experience, ...      1  \n",
       "2  [didnt, today, must, mean, need, take, another...      2  \n",
       "3  [seriously, would, pay, flight, seats, didnt, ...      3  \n",
       "4  [yes, nearly, every, time, fly, vx, ear, worm,...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model tweets600.model.bin ...\n",
      "Done building.\n"
     ]
    }
   ],
   "source": [
    "# train or load the model\n",
    "model = airline_data.build_wordvec(size=600, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length is:  19\n",
      "npy already exists, loading ...\n",
      "Done loading npy file.\n",
      "npy already exists.\n"
     ]
    }
   ],
   "source": [
    "# max_len is the max length of a sentence in our data, this decides the padding\n",
    "max_len = airline_data.max_len(airline_df)\n",
    "# convert our aline data to vector\n",
    "data = airline_data.convert2vec(airline_df, max_len, model, name='airline-3class-600')\n",
    "#data = airline_data.standarize(data)\n",
    "airline_data.save_vec(data, name='airline-3class-600')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can uncomment this to check if the wordvec makes sense\n",
    "# model.wv.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create data that gets fed into classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N, M, D: 8561 19 600\n",
      "(8561, 1, 19, 600)\n",
      "(8561,)\n"
     ]
    }
   ],
   "source": [
    "N, M, D = data.shape\n",
    "print \"N, M, D:\", N, M, D\n",
    "data = data.reshape(-1, 1, M, D).astype(theano.config.floatX) # theano needs this way\n",
    "label = airline_df['class']\n",
    "label = np.int8(label) - 1# seems like theano also needs this\n",
    "print data.shape\n",
    "print label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_cnn(num_epochs=20):\n",
    "    net1 = NeuralNet(\n",
    "        layers=[('input', layers.InputLayer),\n",
    "                ('conv2d1', layers.Conv2DLayer),\n",
    "                ('maxpool1', layers.MaxPool2DLayer),\n",
    "                ('conv2d2', layers.Conv2DLayer),\n",
    "                ('maxpool2', layers.MaxPool2DLayer),\n",
    "                ('dropout1', layers.DropoutLayer),\n",
    "                ('dense', layers.DenseLayer),\n",
    "                ('dropout2', layers.DropoutLayer),\n",
    "                ('output', layers.DenseLayer),\n",
    "                ],\n",
    "        # input layer\n",
    "        input_shape=(None, 1, M, D),\n",
    "        # layer conv2d1\n",
    "        conv2d1_num_filters=50,\n",
    "        conv2d1_filter_size=(3, 3),\n",
    "        conv2d1_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        conv2d1_W=lasagne.init.GlorotUniform(),  \n",
    "        conv2d1_stride=1,\n",
    "        conv2d1_pad=1,\n",
    "        conv2d1_untie_biases=True,\n",
    "        # layer maxpool1\n",
    "        maxpool1_pool_size=(2, 2),    \n",
    "        # layer conv2d2\n",
    "        conv2d2_num_filters=50,\n",
    "        conv2d2_filter_size=(3, 3),\n",
    "        conv2d2_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        conv2d2_stride=1,\n",
    "        conv2d2_pad=1,\n",
    "        conv2d2_untie_biases=True,\n",
    "        # layer maxpool2\n",
    "        maxpool2_pool_size=(2, 2),\n",
    "        # dropout1\n",
    "        dropout1_p=0.5,    \n",
    "        # dense\n",
    "        dense_num_units=5000,\n",
    "        dense_nonlinearity=lasagne.nonlinearities.rectify,    \n",
    "        # dropout2\n",
    "        dropout2_p=0.5,    \n",
    "        # output\n",
    "        output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "        output_num_units=3,\n",
    "        # optimization method params\n",
    "        update=nesterov_momentum,\n",
    "        update_learning_rate=0.01,\n",
    "        update_momentum=0.9,\n",
    "        # train options\n",
    "        train_split = TrainSplit(0.2, stratify=True),\n",
    "        batch_iterator_train = BatchIterator(batch_size=50),\n",
    "        batch_iterator_test = BatchIterator(batch_size=50),\n",
    "        max_epochs=num_epochs,\n",
    "        verbose=1,\n",
    "        )\n",
    "    return net1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_cnn(net, X_train, y_train, model_name='nn_cnn'):\n",
    "    model_file = FILE_PATH+'nn_cnn'\n",
    "    if os.path.isfile(model_file):\n",
    "        print (\"Loading existing model ...\")\n",
    "        net.load_params_from(model_file)\n",
    "    else:\n",
    "        # Train the network\n",
    "        net.fit(X_train, y_train)\n",
    "        nn.save_params_to(model_file)\n",
    "#     preds = net1.predict(X_test)\n",
    "#     cm = confusion_matrix(y_test, preds)\n",
    "#     plt.matshow(cm)\n",
    "#     plt.title('Confusion matrix')\n",
    "#     plt.colorbar()\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 150747953 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  --------  ---------\n",
      "  0  input     1x19x600\n",
      "  1  conv2d1   50x19x600\n",
      "  2  maxpool1  50x9x300\n",
      "  3  conv2d2   50x9x300\n",
      "  4  maxpool2  50x4x150\n",
      "  5  dropout1  50x4x150\n",
      "  6  dense     5000\n",
      "  7  dropout2  5000\n",
      "  8  output    3\n",
      "\n",
      "  epoch    trn loss    val loss    trn/val    valid acc  dur\n",
      "-------  ----------  ----------  ---------  -----------  -----\n",
      "      1     \u001b[36m1.05326\u001b[0m     \u001b[32m1.09896\u001b[0m    0.95842      0.42207  8.16s\n",
      "      2     \u001b[36m1.02418\u001b[0m     \u001b[32m1.09531\u001b[0m    0.93506      0.44250  8.01s\n",
      "      3     \u001b[36m1.01622\u001b[0m     \u001b[32m1.08716\u001b[0m    0.93474      0.44250  7.91s\n",
      "      4     \u001b[36m1.01129\u001b[0m     \u001b[32m1.08490\u001b[0m    0.93215      0.44250  7.91s\n",
      "      5     \u001b[36m1.00323\u001b[0m     \u001b[32m1.07581\u001b[0m    0.93253      0.44542  7.91s\n",
      "      6     \u001b[36m0.99060\u001b[0m     \u001b[32m1.06293\u001b[0m    0.93195      0.46118  7.90s\n",
      "      7     \u001b[36m0.96132\u001b[0m     \u001b[32m1.02863\u001b[0m    0.93456      0.49504  7.91s\n",
      "      8     \u001b[36m0.91106\u001b[0m     \u001b[32m0.97155\u001b[0m    0.93774      0.51956  8.13s\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "cnn= build_cnn()\n",
    "# train\n",
    "train_cnn(cnn, data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize.plot_conv_weights(cnn.layers_['conv2d1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now transfer to svm\n",
    "dense_layer = layers.get_output(cnn.layers_['dense'], deterministic=True)\n",
    "output_layer = layers.get_output(cnn.layers_['output'], deterministic=True)\n",
    "input_var = cnn.layers_['input'].input_var\n",
    "\n",
    "f_output = theano.function([input_var], output_layer)\n",
    "f_dense = theano.function([input_var], dense_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(input_data):\n",
    "    print \"Extracting ... \"\n",
    "    # input_data: n0, 1, n2, n3\n",
    "    n = input_data.shape\n",
    "    return [f_dense(i.reshape(1,1,n[2],n[3])).flatten() for i in input_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# stratified k-fold cross-validation\n",
    "skf = train_test_split(test_size=0.2, stratify=True)\n",
    "n_cv = 1\n",
    "for train_index, val_index in skf.split(data, label):\n",
    "\n",
    "    data_train, data_val = data[train_index], data[val_index]\n",
    "    label_train, label_val = label[train_index], label[val_index]\n",
    "    \n",
    "    freq_train = itemfreq(label_train)\n",
    "    print \"train freq\", freq_train[:,1]\n",
    "    freq_val = itemfreq(label_val)\n",
    "    print \"val freq\", freq_val[:,1]\n",
    "\n",
    "    # pass through cnn\n",
    "    extract1 = extract_features(data_train)\n",
    "    extract2 = extract_features(data_val)\n",
    "    clf = SVC(verbose=True, random_state=42)\n",
    "    print \"Training cv {} ...\".format(n_cv)\n",
    "    clf.fit(extract1, label_train)\n",
    "    acc = clf.score(extract2, label_val)\n",
    "    print acc\n",
    "    print \"\\n\"\n",
    "    n_cv += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
