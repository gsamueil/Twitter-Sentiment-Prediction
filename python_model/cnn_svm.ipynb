{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "from scipy.stats import itemfreq\n",
    "import random\n",
    "import os.path\n",
    "\n",
    "import theano\n",
    "import lasagne\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from nolearn.lasagne import visualize\n",
    "\n",
    "# import user defined load_data to build input data\n",
    "from load_data import Data\n",
    "from utils import save_network\n",
    "from model_predictions import build_cnn\n",
    "from model_predictions import generate_features\n",
    "from model_predictions import extract_features\n",
    "\n",
    "# file path of three directory: data, model and wordvec \n",
    "FILE_PATH = '../files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Airline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading csv: Airline-Sentiment-2-w-AA.csv ...\n",
      "Note: pre-process changes the dataframe inplace.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>What   said</td>\n",
       "      <td>[said]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>plus you ve added commercials to the experie...</td>\n",
       "      <td>[plus, added, commercials, experience, tacky]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I didn t today    Must mean I need to take a...</td>\n",
       "      <td>[today, must, mean, need, take, another, trip]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>it s really aggressive to blast obnoxious  e...</td>\n",
       "      <td>[really, aggressive, blast, obnoxious, enterta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>and it s a really big bad thing about it</td>\n",
       "      <td>[really, big, bad, thing]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0           neutral                                       What   said    \n",
       "1          positive    plus you ve added commercials to the experie...   \n",
       "2           neutral    I didn t today    Must mean I need to take a...   \n",
       "3          negative    it s really aggressive to blast obnoxious  e...   \n",
       "4          negative           and it s a really big bad thing about it   \n",
       "\n",
       "                                           tokenized  \n",
       "0                                             [said]  \n",
       "1      [plus, added, commercials, experience, tacky]  \n",
       "2     [today, must, mean, need, take, another, trip]  \n",
       "3  [really, aggressive, blast, obnoxious, enterta...  \n",
       "4                          [really, big, bad, thing]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_data = Data('Airline-Sentiment-2-w-AA.csv', FILE_PATH)\n",
    "airline_df = airline_data.csv_df(['airline_sentiment', 'text']) # load data\n",
    "airline_data.pre_process(airline_df) # pre-process data\n",
    "# drop neutral\n",
    "# airline_df = airline_data.drop_value(airline_df, 'airline_sentiment', 'neutral')\n",
    "airline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "Done converting categorical to numeric, this changes df.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What   said</td>\n",
       "      <td>[said]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus you ve added commercials to the experie...</td>\n",
       "      <td>[plus, added, commercials, experience, tacky]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I didn t today    Must mean I need to take a...</td>\n",
       "      <td>[today, must, mean, need, take, another, trip]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it s really aggressive to blast obnoxious  e...</td>\n",
       "      <td>[really, aggressive, blast, obnoxious, enterta...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and it s a really big bad thing about it</td>\n",
       "      <td>[really, big, bad, thing]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                                       What   said    \n",
       "1    plus you ve added commercials to the experie...   \n",
       "2    I didn t today    Must mean I need to take a...   \n",
       "3    it s really aggressive to blast obnoxious  e...   \n",
       "4           and it s a really big bad thing about it   \n",
       "\n",
       "                                           tokenized  class  \n",
       "0                                             [said]      2  \n",
       "1      [plus, added, commercials, experience, tacky]      1  \n",
       "2     [today, must, mean, need, take, another, trip]      2  \n",
       "3  [really, aggressive, blast, obnoxious, enterta...      3  \n",
       "4                          [really, big, bad, thing]      3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert categorical value to int class\n",
    "# class_label = {'positive': 1, 'negative': 2}\n",
    "class_label = {'positive': 1, 'neutral': 2, 'negative': 3}\n",
    "\n",
    "airline_df = airline_data.cat2num(airline_df, 'airline_sentiment', class_label, 'class')\n",
    "airline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    9178\n",
       "2    3099\n",
       "1    2363\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets take a look of the \n",
    "airline_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    3099\n",
       "2    3099\n",
       "1    2363\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comment out if do not want class balance\n",
    "airline_df = airline_data.balance_class(airline_df)\n",
    "# and check again\n",
    "airline_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What   said</td>\n",
       "      <td>[said]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus you ve added commercials to the experie...</td>\n",
       "      <td>[plus, added, commercials, experience, tacky]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I didn t today    Must mean I need to take a...</td>\n",
       "      <td>[today, must, mean, need, take, another, trip]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seriously would pay     a flight for seats t...</td>\n",
       "      <td>[seriously, would, pay, flight, seats, playing...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes  nearly every time I fly VX this    ear ...</td>\n",
       "      <td>[yes, nearly, every, time, fly, vx, ear, worm,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                                       What   said    \n",
       "1    plus you ve added commercials to the experie...   \n",
       "2    I didn t today    Must mean I need to take a...   \n",
       "3    seriously would pay     a flight for seats t...   \n",
       "4    yes  nearly every time I fly VX this    ear ...   \n",
       "\n",
       "                                           tokenized  class  \n",
       "0                                             [said]      2  \n",
       "1      [plus, added, commercials, experience, tacky]      1  \n",
       "2     [today, must, mean, need, take, another, trip]      2  \n",
       "3  [seriously, would, pay, flight, seats, playing...      3  \n",
       "4  [yes, nearly, every, time, fly, vx, ear, worm,...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model tweets600.model.bin ...\n",
      "Done building.\n"
     ]
    }
   ],
   "source": [
    "# train or load the model\n",
    "model = airline_data.build_wordvec(size=600, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length is:  21\n",
      ">>> 0 tweets converted ...\n",
      ">>> 2000 tweets converted ...\n",
      ">>> 4000 tweets converted ...\n",
      ">>> 6000 tweets converted ...\n",
      ">>> 8000 tweets converted ...\n",
      "Total 48 not in vocab.\n",
      "Done converting tweets to vec!\n",
      "Saved airline-3class-600 to disk.\n"
     ]
    }
   ],
   "source": [
    "# max_len is the max length of a sentence in our data, this decides the padding\n",
    "max_len = airline_data.max_len(airline_df)\n",
    "# convert our aline data to vector\n",
    "data = airline_data.convert2vec(airline_df, max_len, model, name='airline-3class-600')\n",
    "#data = airline_data.standarize(data)\n",
    "airline_data.save_vec(data, name='airline-3class-600')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can uncomment this to check if the wordvec makes sense\n",
    "# model.wv.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create data that gets fed into classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N, M, D: 8561 21 600\n",
      "(8561, 1, 21, 600)\n",
      "(8561,)\n"
     ]
    }
   ],
   "source": [
    "N, M, D = data.shape\n",
    "print \"N, M, D:\", N, M, D\n",
    "data = data.reshape(-1, 1, M, D).astype(theano.config.floatX) # theano needs this way\n",
    "label = airline_df['class']\n",
    "label = np.int8(label) - 1# seems like theano also needs this\n",
    "print data.shape\n",
    "print label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train our model or load model if it exists\n",
    "def train_cnn(net, X_train, y_train, model_name='nn_cnn1'):\n",
    "    model_file = FILE_PATH+'model/nn_cnn1'\n",
    "    if os.path.isfile(model_file):\n",
    "        print (\"Loading existing model ...\")\n",
    "        net.load_params_from(model_file)\n",
    "    else:\n",
    "        # Train the network\n",
    "        net.fit(X_train, y_train)\n",
    "        net.save_params_to(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 188322953 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  --------  ---------\n",
      "  0  input     1x21x600\n",
      "  1  conv2d1   50x21x600\n",
      "  2  maxpool1  50x10x300\n",
      "  3  conv2d2   50x10x300\n",
      "  4  maxpool2  50x5x150\n",
      "  5  dropout1  50x5x150\n",
      "  6  dense     5000\n",
      "  7  dropout2  5000\n",
      "  8  output    3\n",
      "\n",
      "  epoch    trn loss    val loss    trn/val    valid acc  dur\n",
      "-------  ----------  ----------  ---------  -----------  -----\n",
      "      1     \u001b[36m1.04281\u001b[0m     \u001b[32m1.09614\u001b[0m    0.95134      0.46118  9.43s\n",
      "      2     \u001b[36m1.01777\u001b[0m     \u001b[32m1.08279\u001b[0m    0.93995      0.46760  9.28s\n",
      "      3     \u001b[36m0.99153\u001b[0m     \u001b[32m1.04210\u001b[0m    0.95147      0.48687  9.27s\n",
      "      4     \u001b[36m0.91236\u001b[0m     \u001b[32m0.92173\u001b[0m    0.98983      0.56509  9.27s\n",
      "      5     \u001b[36m0.80753\u001b[0m     \u001b[32m0.89104\u001b[0m    0.90628      0.60187  9.28s\n",
      "      6     \u001b[36m0.75025\u001b[0m     \u001b[32m0.87173\u001b[0m    0.86064      0.62172  9.27s\n",
      "      7     \u001b[36m0.70465\u001b[0m     \u001b[32m0.85997\u001b[0m    0.81940      0.63164  9.27s\n",
      "      8     \u001b[36m0.66532\u001b[0m     \u001b[32m0.85247\u001b[0m    0.78046      0.64156  9.27s\n",
      "      9     \u001b[36m0.61957\u001b[0m     0.86096    0.71963      0.64390  9.28s\n",
      "     10     \u001b[36m0.57675\u001b[0m     \u001b[32m0.84538\u001b[0m    0.68224      0.65849  9.27s\n",
      "     11     \u001b[36m0.53477\u001b[0m     0.88828    0.60202      0.64390  9.27s\n",
      "     12     \u001b[36m0.49044\u001b[0m     0.90900    0.53954      0.64273  9.27s\n",
      "     13     \u001b[36m0.45364\u001b[0m     0.86669    0.52341      0.65616  9.27s\n",
      "     14     \u001b[36m0.39257\u001b[0m     0.98318    0.39929      0.65499  9.27s\n",
      "     15     \u001b[36m0.35571\u001b[0m     0.98569    0.36087      0.64623  9.27s\n",
      "     16     \u001b[36m0.30916\u001b[0m     1.01730    0.30390      0.65558  9.27s\n",
      "     17     \u001b[36m0.29441\u001b[0m     1.10264    0.26701      0.63748  9.27s\n",
      "     18     \u001b[36m0.25034\u001b[0m     1.05937    0.23631      0.64857  9.27s\n",
      "     19     \u001b[36m0.23803\u001b[0m     1.10780    0.21486      0.65207  9.27s\n",
      "     20     \u001b[36m0.21123\u001b[0m     1.15487    0.18291      0.65324  9.27s\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "cnn= build_cnn(M, D)\n",
    "# train\n",
    "train_cnn(cnn, data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/usr/lib/python2.7/dist-packages/matplotlib/pyplot.pyc'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAHlCAYAAADLMORiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKANAEf8HGqjSgRS2nGUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d844d4210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize.plot_conv_weights(cnn.layers_['conv2d1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train freq [1890 2479 2479]\n",
      "val freq [473 620 620]\n",
      "Extracting ... \n",
      "Extracting ... \n",
      "Training cv 1 ...\n",
      "[LibSVM]0.866900175131\n",
      "Time took: 6.87 min\n",
      "\n",
      "\n",
      "train freq [1890 2479 2479]\n",
      "val freq [473 620 620]\n",
      "Extracting ... \n",
      "Extracting ... \n",
      "Training cv 2 ...\n",
      "[LibSVM]0.872737886748\n",
      "Time took: 5.04 min\n",
      "\n",
      "\n",
      "train freq [1890 2479 2479]\n",
      "val freq [473 620 620]\n",
      "Extracting ... \n",
      "Extracting ... \n",
      "Training cv 3 ...\n",
      "[LibSVM]0.871570344425\n",
      "Time took: 5.03 min\n",
      "\n",
      "\n",
      "train freq [1890 2479 2479]\n",
      "val freq [473 620 620]\n",
      "Extracting ... \n",
      "Extracting ... \n",
      "Training cv 4 ...\n",
      "[LibSVM]0.861646234676\n",
      "Time took: 5.01 min\n",
      "\n",
      "\n",
      "train freq [1890 2479 2479]\n",
      "val freq [473 620 620]\n",
      "Extracting ... \n",
      "Extracting ... \n",
      "Training cv 5 ...\n",
      "[LibSVM]0.885580852306\n",
      "Time took: 5.04 min\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now transfer to svm\n",
    "# stratified cross-validation\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "n_cv = 1\n",
    "for train_index, val_index in sss.split(data, label):\n",
    "    t1 = time.time()\n",
    "    data_train, data_val = data[train_index], data[val_index]\n",
    "    label_train, label_val = label[train_index], label[val_index]\n",
    "    \n",
    "    freq_train = itemfreq(label_train)\n",
    "    print \"train freq\", freq_train[:,1]\n",
    "    freq_val = itemfreq(label_val)\n",
    "    print \"val freq\", freq_val[:,1]\n",
    "\n",
    "    # pass through cnn\n",
    "    extract_train = extract_features(cnn, data_train)\n",
    "    extract_val = extract_features(cnn, data_val)\n",
    "    clf = SVC(verbose=True, random_state=None)\n",
    "    print \"Training cv {} ...\".format(n_cv)\n",
    "    clf.fit(extract_train, label_train)\n",
    "    acc = clf.score(extract_val, label_val)\n",
    "    t2 = time.time()\n",
    "    print acc\n",
    "    print \"Time took: {0:.2f} min\".format((t2-t1)/60)\n",
    "    print \"\\n\"\n",
    "    n_cv += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../files/model/cnn-svm-final.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "joblib.dump(clf, FILE_PATH+'model/cnn-svm-final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
