{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5105 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1080 (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "# This file makes predictions on incoming data and perform basic analysis.\n",
    "import pandas as pd\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import nltk\n",
    "from load_data import Data\n",
    "from utils import *\n",
    "\n",
    "FILE_PATH = '/home/sam/Hhd/twitter_sentiment/'\n",
    "# FILE_PATH = '/home/sam/Data/twitter_sentiment/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading csv: air.csv ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @dimitrivegas: For more info... please visi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@AmericanAir I don't think you do!! 90% of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@AmericanAir they said it was due to size and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon, SeaWorld, @AmericanAir Downgraded - @S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Julie, @AmericanAir manager in Bozeman, MT, th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  RT @dimitrivegas: For more info... please visi...\n",
       "1  @AmericanAir I don't think you do!! 90% of the...\n",
       "2  @AmericanAir they said it was due to size and ...\n",
       "3  Amazon, SeaWorld, @AmericanAir Downgraded - @S...\n",
       "4  Julie, @AmericanAir manager in Bozeman, MT, th..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"air.csv\"\n",
    "\n",
    "test_data = Data(file_name, FILE_PATH)\n",
    "test_df = test_data.csv_df(['text'])\n",
    "# make a copy of the original tweets for later use\n",
    "original_df = test_df.copy()\n",
    "# original tweets\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: pre-process changes the dataframe inplace.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT  For more info please visit this shortcut l...</td>\n",
       "      <td>[info, please, visit, shortcut, eduaubdedubu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I dont think you do  of the flights Ive had w...</td>\n",
       "      <td>[dont, think, flights, ive, bags, delayed, fli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they said it was due to size and I have never...</td>\n",
       "      <td>[said, due, size, never, problem, fitting, ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon SeaWorld  Downgraded   blog</td>\n",
       "      <td>[amazon, seaworld, downgraded, blog]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Julie  manager in Bozeman MT thanks much for t...</td>\n",
       "      <td>[manager, mt, thanks, much, upgrade, yesterday...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  RT  For more info please visit this shortcut l...   \n",
       "1   I dont think you do  of the flights Ive had w...   \n",
       "2   they said it was due to size and I have never...   \n",
       "3               Amazon SeaWorld  Downgraded   blog     \n",
       "4  Julie  manager in Bozeman MT thanks much for t...   \n",
       "\n",
       "                                           tokenized  \n",
       "0      [info, please, visit, shortcut, eduaubdedubu]  \n",
       "1  [dont, think, flights, ive, bags, delayed, fli...  \n",
       "2  [said, due, size, never, problem, fitting, ame...  \n",
       "3               [amazon, seaworld, downgraded, blog]  \n",
       "4  [manager, mt, thanks, much, upgrade, yesterday...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-process data(same as how we trained)\n",
    "test_data.pre_process(test_df) \n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model tweets600.model.bin ...\n",
      "Done building.\n",
      "max sentence length is:  18\n",
      "npy already exists, loading ...\n",
      "Done loading npy file.\n",
      "npy already exists.\n"
     ]
    }
   ],
   "source": [
    "# then convert using word2vec\n",
    "model = test_data.build_wordvec(size=600, verbose=False)\n",
    "# take a look of the max_len of testing. although we still have to use max_len from train\n",
    "max_len_test = test_data.max_len(test_df)\n",
    "max_len_train = 19\n",
    "data = test_data.convert2vec(test_df, max_len_train, model, name='test')\n",
    "test_data.save_vec(data, name='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load trained model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cnn(M, D, input_var=None):\n",
    "    network = lasagne.layers.InputLayer(shape=(None, 1, M, D), input_var=input_var)\n",
    "    network = lasagne.layers.Conv2DLayer(network, num_filters=40, filter_size=(3, 3), \\\n",
    "                                         nonlinearity=lasagne.nonlinearities.rectify, \\\n",
    "                                         W=lasagne.init.GlorotUniform(), pad=0, stride=(1, 1), \\\n",
    "                                         untie_biases=True)\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "    network = lasagne.layers.Conv2DLayer(network, num_filters=50, filter_size=(3, 3), \\\n",
    "                                         nonlinearity=lasagne.nonlinearities.rectify, pad=0, \\\n",
    "                                         stride=(1, 1), untie_biases=True)\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "    network = lasagne.layers.DenseLayer(lasagne.layers.dropout(network, p=0.5), num_units=6000, \\\n",
    "                                        nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    network = lasagne.layers.DenseLayer(lasagne.layers.dropout(network, p=0.5), num_units=3,  \\\n",
    "                                        nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    return network\n",
    "\n",
    "def make_prediction(data):\n",
    "    \n",
    "    N, M, D = data.shape\n",
    "    print \"N, M, D:\", N, M, D\n",
    "    data = data.reshape(-1, 1, M, D).astype(theano.config.floatX) # theano needs this way\n",
    "    \n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "    network = cnn(M, D, input_var)\n",
    "    \n",
    "    # now load model and do predictions\n",
    "    saved_params = load_network(FILE_PATH, \"cnn.npz\")\n",
    "    lasagne.layers.set_all_param_values(network, saved_params)\n",
    "    \n",
    "    # define prediction function\n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    predict_label = T.argmax(test_prediction,axis=1)\n",
    "    test_fn = theano.function([input_var], predict_label)\n",
    "    \n",
    "    test_pred = test_fn(data) + 1\n",
    "    \n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N, M, D: 1000 19 600\n"
     ]
    }
   ],
   "source": [
    "# get predictions\n",
    "test_predictions = make_prediction(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the predictions with raw tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    643\n",
      "2    224\n",
      "1    133\n",
      "Name: prediction, dtype: int64\n",
      "prediction\n",
      "Done converting categorical to numeric, this changes df.\n",
      "[ 'RT @dimitrivegas: For more info... please visit this shortcut link! <ed><U+00A0><U+00BD><ed><U+00B8><U+0085> @AmericanAir https://t.co/M8whrVEKMc'\n",
      " 'neutral']\n",
      "[ \"@AmericanAir I don't think you do!! 90% of the flights I've had with you my bags delayed, flights cancelled, bookings cancelled etc.\"\n",
      " 'negative']\n",
      "[ '@AmericanAir they said it was due to size and I have never once had a problem fitting it on American flights. New airline here I come'\n",
      " 'negative']\n",
      "[ 'Amazon, SeaWorld, @AmericanAir Downgraded - @Schaeffers (blog) : https://t.co/g0QTn38IH4'\n",
      " 'neutral']\n",
      "[ 'Julie, @AmericanAir manager in Bozeman, MT, thanks much for the upgrade after yesterday. Glad to have met you and wish you the best!'\n",
      " 'positive']\n",
      "[ 'Is San Francisco America\\x92s New Art Capital? In Celebrated Living for @AmericanAir #WeAreTravelMedia\\x85 https://t.co/RrulHzMw03'\n",
      " 'negative']\n",
      "[ \"@AmericanAir nah, you've had multiple chances this tear alone. Inexcusable customer service and just not giving a dam, I'm over it!!\"\n",
      " 'negative']\n",
      "[ '@AmericanAir with that totally random flight cancellation <ed><U+00A0><U+00BD><ed><U+00B1><U+0080>'\n",
      " 'negative']\n",
      "[\"@AmericanAir what isn't going on is the problem.\" 'negative']\n",
      "[ 'Baffled by @AmericanAir boarding  passengers with full knowledge that the captain is still on an inbound  flight. SMH. #FAIL'\n",
      " 'negative']\n"
     ]
    }
   ],
   "source": [
    "test_df['prediction'] = test_predictions\n",
    "# lets take a look of the \n",
    "print test_df['prediction'].value_counts()\n",
    "\n",
    "# write to original dataframe\n",
    "original_df['prediction'] = test_predictions\n",
    "# convert numeric prediction to categorical\n",
    "class_label = {1:'positive', 2: 'neutral', 3: 'negative'}\n",
    "original_df = test_data.num2cat(original_df, 'prediction', class_label)\n",
    "# take a quick look at the prediction and its corresponding tweet\n",
    "for i in range(10):\n",
    "    print original_df.values[i,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to csv\n",
    "original_df.to_csv(\"airline_predicted.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most top frequent words from each sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "[('great', 49), ('thanks', 38), ('helps', 18), ('thank', 18), ('sharing', 11), ('everyone', 11), ('news', 11), ('experience', 10), ('fly', 10), ('flight', 10), ('big', 10), ('guests', 9), ('smoothly', 9), ('cognos', 9), ('analytics', 9), ('run', 9), ('trip', 9), ('busi', 8), ('amazing', 8), ('making', 7)]\n",
      "Neutral\n",
      "[('visit', 53), ('please', 50), ('eduaubdedubu', 48), ('shortcut', 48), ('info', 48), ('w', 17), ('watch', 14), ('award', 11), ('time', 10), ('great', 9)]\n",
      "Negative\n",
      "[('flight', 157), ('time', 52), ('get', 50), ('service', 39), ('im', 37), ('us', 37), ('hours', 34), ('delayed', 31), ('plane', 30), ('flights', 29), ('thanks', 28), ('dont', 28), ('please', 28), ('one', 25), ('customer', 25), ('home', 25), ('cant', 24), ('worst', 24), ('help', 24), ('gate', 23)]\n"
     ]
    }
   ],
   "source": [
    "# look at most frequent words in different groups\n",
    "print \"Positive\"\n",
    "print most_freq(test_df, 1, top=20)\n",
    "print \"Neutral\"\n",
    "print most_freq(test_df, 2)\n",
    "print \"Negative\"\n",
    "print most_freq(test_df, 3, top=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look up the context of those most frequent word, e.g. *gate*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebecca: @Delta gave us a coloring book at the gate and the TSA agents gave them stickers after we went through security! @AmericanAir\n",
      "@AmericanAir If you simcerly want that, please train your gate agents appropriately.\n",
      "Another travel favorite: land 30 min early. Wait on tarmac for 40 for gate. Then bags not out 40 minutes later. @AmericanAir @PHXSkyHarbor\n",
      "@Delta : delay @JFK to ATL due to technical issues. Sat inside plane (no drinks) at gate for 2.5 hrs and after night long stay in airport\n",
      "@DELTA gate agents at B18 must be having a bad day.  Disappointing service.\n",
      "Rebecca: @Delta gave us a coloring book at the gate and the TSA agents gave them stickers after we went through security! @AmericanAir\n",
      "Now to hurry up and wait... at least @delta usually gets out of here on time #travel (@ Gate 60 in Kansas City, MO) https://t.co/N3K4mseHNm\n",
      "@Delta get your act together and staff your damn gate desk. Loved ones want to go home! #LAX\n",
      "I'd rather walk home than deal with another high strung, crabby @Delta gate agent (DFW E12). Must be their job to hassle me. #DoneWithDelta\n",
      "I've been flying JFK to LAX for the past 3 years why is there still a traffic issue when arriving to the gate. Huge inconvenience @Delta\n"
     ]
    }
   ],
   "source": [
    "# we can take a look of the tweets where the frequent word is mentioned, e.g. lookup 'help' in negative tweets\n",
    "look_up(original_df, test_df, 'gate', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
