{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5105 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1080 (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "from scipy.stats import itemfreq\n",
    "import random\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# import user defined load_data to build input data\n",
    "from load_data import Data\n",
    "\n",
    "FILE_PATH = '/home/sam/Hhd/twitter_sentiment/'\n",
    "# FILE_PATH = '/home/sam/Data/twitter_sentiment/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline-Sentiment-2-w-AA.csv  negative.json  questions-words.txt  text8\r\n",
      "nba.json                      positive.json  stream.json          trump.json\r\n"
     ]
    }
   ],
   "source": [
    "ls '/home/sam/Hhd/twitter_sentiment/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ls '/home/sam/Data/twitter_sentiment/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Airline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading csv: Airline-Sentiment-2-w-AA.csv ...\n",
      "Note: pre_process changes the dataframe inplace.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>plus youve added commercials to the experienc...</td>\n",
       "      <td>[plus, youve, added, commercials, experience, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>its really aggressive to blast obnoxious ente...</td>\n",
       "      <td>[really, aggressive, blast, obnoxious, enterta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>and its a really big bad thing about it</td>\n",
       "      <td>[really, big, bad, thing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>seriously would pay  a flight for seats that ...</td>\n",
       "      <td>[seriously, would, pay, flight, seats, didnt, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>yes nearly every time I fly VX this ear worm ...</td>\n",
       "      <td>[yes, nearly, every, time, fly, vx, ear, worm,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0          positive   plus youve added commercials to the experienc...   \n",
       "1          negative   its really aggressive to blast obnoxious ente...   \n",
       "2          negative            and its a really big bad thing about it   \n",
       "3          negative   seriously would pay  a flight for seats that ...   \n",
       "4          positive   yes nearly every time I fly VX this ear worm ...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [plus, youve, added, commercials, experience, ...  \n",
       "1  [really, aggressive, blast, obnoxious, enterta...  \n",
       "2                          [really, big, bad, thing]  \n",
       "3  [seriously, would, pay, flight, seats, didnt, ...  \n",
       "4  [yes, nearly, every, time, fly, vx, ear, worm,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_data = Data('Airline-Sentiment-2-w-AA.csv', FILE_PATH)\n",
    "airline_df = airline_data.csv_df(['airline_sentiment', 'text']) # load data\n",
    "airline_data.pre_process(airline_df) # pre-process data\n",
    "# drop neutral\n",
    "airline_df = airline_df.drop(airline_df[airline_df['airline_sentiment']=='neutral'].index)\n",
    "airline_df = airline_df.reset_index(drop=True)\n",
    "airline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plus youve added commercials to the experienc...</td>\n",
       "      <td>[plus, youve, added, commercials, experience, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>its really aggressive to blast obnoxious ente...</td>\n",
       "      <td>[really, aggressive, blast, obnoxious, enterta...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and its a really big bad thing about it</td>\n",
       "      <td>[really, big, bad, thing]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seriously would pay  a flight for seats that ...</td>\n",
       "      <td>[seriously, would, pay, flight, seats, didnt, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes nearly every time I fly VX this ear worm ...</td>\n",
       "      <td>[yes, nearly, every, time, fly, vx, ear, worm,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0   plus youve added commercials to the experienc...   \n",
       "1   its really aggressive to blast obnoxious ente...   \n",
       "2            and its a really big bad thing about it   \n",
       "3   seriously would pay  a flight for seats that ...   \n",
       "4   yes nearly every time I fly VX this ear worm ...   \n",
       "\n",
       "                                           tokenized  class  \n",
       "0  [plus, youve, added, commercials, experience, ...      1  \n",
       "1  [really, aggressive, blast, obnoxious, enterta...      2  \n",
       "2                          [really, big, bad, thing]      2  \n",
       "3  [seriously, would, pay, flight, seats, didnt, ...      2  \n",
       "4  [yes, nearly, every, time, fly, vx, ear, worm,...      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert categorical value to int class\n",
    "# class_label = {'positive': 1, 'neutral': 2, 'negative': 3}\n",
    "class_label = {'positive': 1, 'negative': 2}\n",
    "airline_df['class'] = airline_df['airline_sentiment'].apply(lambda x: class_label[x])\n",
    "airline_df.drop('airline_sentiment', inplace=True, axis=1)\n",
    "airline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    9178\n",
      "1    2363\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# take a look of the class\n",
    "class_counts = airline_df['class'].value_counts()\n",
    "print class_counts\n",
    "# let us randomly drop some class 3 so that it is on par with rest of classes\n",
    "# n3 = class_counts.values[0]\n",
    "n2 = class_counts.values[0]\n",
    "n1 = class_counts.values[1]\n",
    "random.seed(42)\n",
    "drop_n2 = random.sample(range(n2), n2-n1) # sample without replacement\n",
    "n2_index = airline_df[airline_df['class']==2].index.values\n",
    "airline_df.drop(n2_index[drop_n2], axis=0, inplace=True)\n",
    "airline_df = airline_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    2363\n",
       "1    2363\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plus youve added commercials to the experienc...</td>\n",
       "      <td>[plus, youve, added, commercials, experience, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seriously would pay  a flight for seats that ...</td>\n",
       "      <td>[seriously, would, pay, flight, seats, didnt, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes nearly every time I fly VX this ear worm ...</td>\n",
       "      <td>[yes, nearly, every, time, fly, vx, ear, worm,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Well I didntbut NOW I DO D</td>\n",
       "      <td>[well, didntbut]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it was amazing and arrived an hour early Your...</td>\n",
       "      <td>[amazing, arrived, hour, early, youre, good]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0   plus youve added commercials to the experienc...   \n",
       "1   seriously would pay  a flight for seats that ...   \n",
       "2   yes nearly every time I fly VX this ear worm ...   \n",
       "3                         Well I didntbut NOW I DO D   \n",
       "4   it was amazing and arrived an hour early Your...   \n",
       "\n",
       "                                           tokenized  class  \n",
       "0  [plus, youve, added, commercials, experience, ...      1  \n",
       "1  [seriously, would, pay, flight, seats, didnt, ...      2  \n",
       "2  [yes, nearly, every, time, fly, vx, ear, worm,...      1  \n",
       "3                                   [well, didntbut]      1  \n",
       "4       [amazing, arrived, hour, early, youre, good]      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model tweets500.model.bin ...\n",
      "Done building.\n"
     ]
    }
   ],
   "source": [
    "# train or load the model\n",
    "model = airline_data.build_wordvec(size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length is:  21\n",
      "npy already exists, loading ...\n",
      "Done loading npy file.\n",
      "npy already exists.\n"
     ]
    }
   ],
   "source": [
    "max_len = airline_data.max_len(airline_df)\n",
    "data = airline_data.convert2vec(airline_df, max_len, model, name='airline500')\n",
    "airline_data.save_vec(data, name='airline500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.wv.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N, M, D: 4726 21 500\n",
      "(4726, 1, 21, 500)\n",
      "(4726,)\n"
     ]
    }
   ],
   "source": [
    "N, M, D = data.shape\n",
    "print \"N, M, D:\", N, M, D\n",
    "data = data.reshape(-1, 1, M, D).astype(theano.config.floatX) # theano needs this way\n",
    "label = airline_df['class']\n",
    "label = np.int8(label) - 1# seems like theano also needs this\n",
    "print data.shape\n",
    "print label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ############################# Batch iterator ###############################\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ##################### Build the CNN neural network model #######################\n",
    "def build_cnn(input_var=None):\n",
    "    # We create a CNN of two convolution + pooling stages\n",
    "    # and a fully-connected hidden layer in front of the output layer.\n",
    "\n",
    "    # Input layer, as usual:\n",
    "    network = lasagne.layers.InputLayer(shape=(None, 1, M, D), input_var=input_var)\n",
    "    # This time we do not apply input dropout, as it tends to work less well\n",
    "    # for convolutional layers.\n",
    "\n",
    "    # Convolutional layer with 32 kernels of size 3x3. Strided and padded\n",
    "    # convolutions are supported as well; see the docstring.\n",
    "    network = lasagne.layers.Conv2DLayer(network, num_filters=40, filter_size=(3, 3), \\\n",
    "                                         nonlinearity=lasagne.nonlinearities.rectify, \\\n",
    "                                         W=lasagne.init.GlorotUniform(), pad=0, stride=(1, 1), \\\n",
    "                                         untie_biases=True)\n",
    "    # Max-pooling layer of factor 2 in both dimensions:\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "\n",
    "    # Another convolution with 32 3x3 kernels, and another 2x2 pooling:\n",
    "    network = lasagne.layers.Conv2DLayer(network, num_filters=40, filter_size=(3, 5), \\\n",
    "                                         nonlinearity=lasagne.nonlinearities.rectify, pad=0, \\\n",
    "                                         stride=(1, 1), untie_biases=True)\n",
    "    \n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "\n",
    "    # A fully-connected layer of ??? units with 50% dropout on its inputs:\n",
    "    network = lasagne.layers.DenseLayer(lasagne.layers.dropout(network, p=0.5), num_units=1000, \\\n",
    "                                        nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    # And, finally, the 10-unit output layer with 50% dropout on its inputs:\n",
    "    network = lasagne.layers.DenseLayer(lasagne.layers.dropout(network, p=0.5), num_units=3,  \\\n",
    "                                        nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ############################## Main program ################################\n",
    "def train_cnn(X_train, y_train, X_val, y_val, X_test, num_epochs=300):\n",
    "    # Load the dataset\n",
    "    print(\"Loading data...\")\n",
    "    #X_train, y_train, X_val, y_val, X_test = load_dataset()\n",
    "    # Prepare Theano variables for inputs and targets\n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    # Create neural network model (depending on first command line parameter)\n",
    "    print(\"Building model and compiling functions...\")\n",
    "\n",
    "    network = build_cnn(input_var)\n",
    "    accuracy_rate = []\n",
    "\n",
    "    # Create a loss expression for training, i.e., a scalar objective we want\n",
    "    # to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "    # We could add some weight decay as well here, see lasagne.regularization.\n",
    "\n",
    "    # Create update expressions for training, i.e., how to modify the\n",
    "    # parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "    # Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=0.005, momentum=0.9)\n",
    "\n",
    "    # Create a loss expression for validation/testing. The crucial difference\n",
    "    # here is that we do a deterministic forward pass through the network,\n",
    "    # disabling dropout layers.\n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    # print test_prediction.flatten()\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction, target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "    # As a bonus, also create an expression for the classification accuracy:\n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var), dtype=theano.config.floatX)\n",
    "\n",
    "    predict_label = T.argmax(test_prediction,axis=1)\n",
    "\n",
    "    # Compile a function performing a training step on a mini-batch (by giving\n",
    "    # the updates dictionary) and returning the corresponding training loss:\n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "    # Compile a second function computing the validation loss and accuracy:\n",
    "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "    test_fn = theano.function([input_var], predict_label)\n",
    "\n",
    "    # Finally, launch the training loop.\n",
    "    print(\"Starting training...\")\n",
    "    # We iterate over epochs:\n",
    "    for epoch in range(num_epochs):\n",
    "#         start_time = time.time()\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        for batch in iterate_minibatches(X_train, y_train, 50, shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            train_batches += 1\n",
    "    \n",
    "#         train_err = train_fn(X_train, y_train)\n",
    "        # And a full pass over the validation data:\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(X_val, y_val, 50, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "    \n",
    "#         val_err, val_acc = val_fn(X_val, y_val)\n",
    "#         accuracy_rate.append(val_acc)\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "        print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "        print(\"  validation accuracy:\\t\\t{:.2f} %\".format(val_acc / val_batches * 100))\n",
    "\n",
    "            \n",
    "    # After training, we compute and print the test error:\n",
    "    test_pred = test_fn(X_test[:50,:,:])\n",
    "    print set(test_pred)\n",
    "\n",
    "    # After training, we compute and print the test error:\n",
    "#     test_err = 0\n",
    "#     test_acc = 0\n",
    "#     test_batches = 0\n",
    "#     for batch in iterate_minibatches(X_test, y_test, 500, shuffle=False):\n",
    "#         inputs, targets = batch\n",
    "#         err, acc = val_fn(inputs, targets)\n",
    "#         test_err += err\n",
    "#         test_acc += acc\n",
    "#         test_batches += 1\n",
    "#     print(\"Final results:\")\n",
    "#     print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "#     print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "#         test_acc / test_batches * 100))\n",
    "\n",
    "    # Optionally, you could now dump the network weights to a file like this:\n",
    "    # np.savez('model.npz', *lasagne.layers.get_all_param_values(network))\n",
    "    #\n",
    "    # And load them again later on like this:\n",
    "    # with np.load('model.npz') as f:\n",
    "    #     param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    # lasagne.layers.set_all_param_values(network, param_values)\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TRAIN:', array([1554, 1555, 1556, ..., 4723, 4724, 4725]), 'TEST:', array([   0,    1,    2, ..., 1598, 1599, 1600]))\n",
      "train freq [1575 1575]\n",
      "val freq [788 788]\n",
      "Loading data...\n",
      "Building model and compiling functions...\n",
      "Starting training...\n",
      "Epoch 1 of 300 took 1.140s\n",
      "  training loss:\t\t0.842980\n",
      "  validation loss:\t\t0.694531\n",
      "  validation accuracy:\t\t61.42 %\n",
      "Epoch 2 of 300 took 1.193s\n",
      "  training loss:\t\t0.663435\n",
      "  validation loss:\t\t0.652688\n",
      "  validation accuracy:\t\t63.42 %\n",
      "Epoch 3 of 300 took 1.145s\n",
      "  training loss:\t\t0.647303\n",
      "  validation loss:\t\t0.667760\n",
      "  validation accuracy:\t\t61.61 %\n",
      "Epoch 4 of 300 took 1.205s\n",
      "  training loss:\t\t0.642242\n",
      "  validation loss:\t\t0.640208\n",
      "  validation accuracy:\t\t63.81 %\n",
      "Epoch 5 of 300 took 1.154s\n",
      "  training loss:\t\t0.631512\n",
      "  validation loss:\t\t0.640156\n",
      "  validation accuracy:\t\t63.42 %\n",
      "Epoch 6 of 300 took 1.146s\n",
      "  training loss:\t\t0.629034\n",
      "  validation loss:\t\t0.634392\n",
      "  validation accuracy:\t\t65.74 %\n",
      "Epoch 7 of 300 took 1.146s\n",
      "  training loss:\t\t0.623528\n",
      "  validation loss:\t\t0.638886\n",
      "  validation accuracy:\t\t63.48 %\n",
      "Epoch 8 of 300 took 1.206s\n",
      "  training loss:\t\t0.623625\n",
      "  validation loss:\t\t0.629027\n",
      "  validation accuracy:\t\t64.13 %\n",
      "Epoch 9 of 300 took 1.166s\n",
      "  training loss:\t\t0.619981\n",
      "  validation loss:\t\t0.624573\n",
      "  validation accuracy:\t\t65.55 %\n",
      "Epoch 10 of 300 took 1.143s\n",
      "  training loss:\t\t0.608797\n",
      "  validation loss:\t\t0.627445\n",
      "  validation accuracy:\t\t64.52 %\n",
      "Epoch 11 of 300 took 1.165s\n",
      "  training loss:\t\t0.601490\n",
      "  validation loss:\t\t0.614625\n",
      "  validation accuracy:\t\t64.84 %\n",
      "Epoch 12 of 300 took 1.199s\n",
      "  training loss:\t\t0.595336\n",
      "  validation loss:\t\t0.605405\n",
      "  validation accuracy:\t\t66.26 %\n",
      "Epoch 13 of 300 took 1.187s\n",
      "  training loss:\t\t0.583323\n",
      "  validation loss:\t\t0.595057\n",
      "  validation accuracy:\t\t69.81 %\n",
      "Epoch 14 of 300 took 1.194s\n",
      "  training loss:\t\t0.569048\n",
      "  validation loss:\t\t0.579276\n",
      "  validation accuracy:\t\t70.52 %\n",
      "Epoch 15 of 300 took 1.163s\n",
      "  training loss:\t\t0.551901\n",
      "  validation loss:\t\t0.563523\n",
      "  validation accuracy:\t\t70.65 %\n",
      "Epoch 16 of 300 took 1.146s\n",
      "  training loss:\t\t0.523832\n",
      "  validation loss:\t\t0.542185\n",
      "  validation accuracy:\t\t74.71 %\n",
      "Epoch 17 of 300 took 1.190s\n",
      "  training loss:\t\t0.502317\n",
      "  validation loss:\t\t0.525694\n",
      "  validation accuracy:\t\t75.68 %\n",
      "Epoch 18 of 300 took 1.197s\n",
      "  training loss:\t\t0.468536\n",
      "  validation loss:\t\t0.520491\n",
      "  validation accuracy:\t\t75.16 %\n",
      "Epoch 19 of 300 took 1.145s\n",
      "  training loss:\t\t0.433937\n",
      "  validation loss:\t\t0.474493\n",
      "  validation accuracy:\t\t77.81 %\n",
      "Epoch 20 of 300 took 1.194s\n",
      "  training loss:\t\t0.409129\n",
      "  validation loss:\t\t0.461045\n",
      "  validation accuracy:\t\t79.10 %\n",
      "Epoch 21 of 300 took 1.181s\n",
      "  training loss:\t\t0.388852\n",
      "  validation loss:\t\t0.471212\n",
      "  validation accuracy:\t\t77.61 %\n",
      "Epoch 22 of 300 took 1.170s\n",
      "  training loss:\t\t0.366189\n",
      "  validation loss:\t\t0.433632\n",
      "  validation accuracy:\t\t81.23 %\n",
      "Epoch 23 of 300 took 1.162s\n",
      "  training loss:\t\t0.344286\n",
      "  validation loss:\t\t0.426662\n",
      "  validation accuracy:\t\t80.77 %\n",
      "Epoch 24 of 300 took 1.161s\n",
      "  training loss:\t\t0.332505\n",
      "  validation loss:\t\t0.435552\n",
      "  validation accuracy:\t\t80.13 %\n",
      "Epoch 25 of 300 took 1.157s\n",
      "  training loss:\t\t0.314333\n",
      "  validation loss:\t\t0.425519\n",
      "  validation accuracy:\t\t80.19 %\n",
      "Epoch 26 of 300 took 1.156s\n",
      "  training loss:\t\t0.289504\n",
      "  validation loss:\t\t0.415442\n",
      "  validation accuracy:\t\t81.48 %\n",
      "Epoch 27 of 300 took 1.159s\n",
      "  training loss:\t\t0.286468\n",
      "  validation loss:\t\t0.410062\n",
      "  validation accuracy:\t\t81.81 %\n",
      "Epoch 28 of 300 took 1.157s\n",
      "  training loss:\t\t0.257836\n",
      "  validation loss:\t\t0.424849\n",
      "  validation accuracy:\t\t80.97 %\n",
      "Epoch 29 of 300 took 1.139s\n",
      "  training loss:\t\t0.245517\n",
      "  validation loss:\t\t0.407557\n",
      "  validation accuracy:\t\t82.00 %\n",
      "Epoch 30 of 300 took 1.167s\n",
      "  training loss:\t\t0.224563\n",
      "  validation loss:\t\t0.419976\n",
      "  validation accuracy:\t\t80.71 %\n",
      "Epoch 31 of 300 took 1.141s\n",
      "  training loss:\t\t0.222594\n",
      "  validation loss:\t\t0.410357\n",
      "  validation accuracy:\t\t82.06 %\n",
      "Epoch 32 of 300 took 1.140s\n",
      "  training loss:\t\t0.202095\n",
      "  validation loss:\t\t0.425522\n",
      "  validation accuracy:\t\t80.84 %\n",
      "Epoch 33 of 300 took 1.141s\n",
      "  training loss:\t\t0.185953\n",
      "  validation loss:\t\t0.420133\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 34 of 300 took 1.159s\n",
      "  training loss:\t\t0.180215\n",
      "  validation loss:\t\t0.413412\n",
      "  validation accuracy:\t\t82.19 %\n",
      "Epoch 35 of 300 took 1.150s\n",
      "  training loss:\t\t0.160574\n",
      "  validation loss:\t\t0.428103\n",
      "  validation accuracy:\t\t82.26 %\n",
      "Epoch 36 of 300 took 1.154s\n",
      "  training loss:\t\t0.152179\n",
      "  validation loss:\t\t0.472025\n",
      "  validation accuracy:\t\t79.74 %\n",
      "Epoch 37 of 300 took 1.162s\n",
      "  training loss:\t\t0.141438\n",
      "  validation loss:\t\t0.429002\n",
      "  validation accuracy:\t\t82.32 %\n",
      "Epoch 38 of 300 took 1.145s\n",
      "  training loss:\t\t0.128778\n",
      "  validation loss:\t\t0.423321\n",
      "  validation accuracy:\t\t82.84 %\n",
      "Epoch 39 of 300 took 1.158s\n",
      "  training loss:\t\t0.126554\n",
      "  validation loss:\t\t0.508283\n",
      "  validation accuracy:\t\t79.55 %\n",
      "Epoch 40 of 300 took 1.140s\n",
      "  training loss:\t\t0.111803\n",
      "  validation loss:\t\t0.440280\n",
      "  validation accuracy:\t\t82.32 %\n",
      "Epoch 41 of 300 took 1.140s\n",
      "  training loss:\t\t0.104936\n",
      "  validation loss:\t\t0.437819\n",
      "  validation accuracy:\t\t82.39 %\n",
      "Epoch 42 of 300 took 1.141s\n",
      "  training loss:\t\t0.097331\n",
      "  validation loss:\t\t0.467584\n",
      "  validation accuracy:\t\t81.61 %\n",
      "Epoch 43 of 300 took 1.140s\n",
      "  training loss:\t\t0.087508\n",
      "  validation loss:\t\t0.471450\n",
      "  validation accuracy:\t\t82.19 %\n",
      "Epoch 44 of 300 took 1.141s\n",
      "  training loss:\t\t0.077762\n",
      "  validation loss:\t\t0.486707\n",
      "  validation accuracy:\t\t81.23 %\n",
      "Epoch 45 of 300 took 1.140s\n",
      "  training loss:\t\t0.083085\n",
      "  validation loss:\t\t0.462654\n",
      "  validation accuracy:\t\t82.58 %\n",
      "Epoch 46 of 300 took 1.140s\n",
      "  training loss:\t\t0.077872\n",
      "  validation loss:\t\t0.467202\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 47 of 300 took 1.140s\n",
      "  training loss:\t\t0.068833\n",
      "  validation loss:\t\t0.474194\n",
      "  validation accuracy:\t\t81.81 %\n",
      "Epoch 48 of 300 took 1.141s\n",
      "  training loss:\t\t0.061694\n",
      "  validation loss:\t\t0.489648\n",
      "  validation accuracy:\t\t81.87 %\n",
      "Epoch 49 of 300 took 1.141s\n",
      "  training loss:\t\t0.058827\n",
      "  validation loss:\t\t0.483870\n",
      "  validation accuracy:\t\t82.32 %\n",
      "Epoch 50 of 300 took 1.141s\n",
      "  training loss:\t\t0.054869\n",
      "  validation loss:\t\t0.501926\n",
      "  validation accuracy:\t\t81.94 %\n",
      "Epoch 51 of 300 took 1.141s\n",
      "  training loss:\t\t0.055620\n",
      "  validation loss:\t\t0.520846\n",
      "  validation accuracy:\t\t81.68 %\n",
      "Epoch 52 of 300 took 1.141s\n",
      "  training loss:\t\t0.049637\n",
      "  validation loss:\t\t0.518662\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 53 of 300 took 1.142s\n",
      "  training loss:\t\t0.047916\n",
      "  validation loss:\t\t0.525816\n",
      "  validation accuracy:\t\t81.94 %\n",
      "Epoch 54 of 300 took 1.140s\n",
      "  training loss:\t\t0.044902\n",
      "  validation loss:\t\t0.519744\n",
      "  validation accuracy:\t\t81.87 %\n",
      "Epoch 55 of 300 took 1.141s\n",
      "  training loss:\t\t0.042235\n",
      "  validation loss:\t\t0.560859\n",
      "  validation accuracy:\t\t80.58 %\n",
      "Epoch 56 of 300 took 1.141s\n",
      "  training loss:\t\t0.040301\n",
      "  validation loss:\t\t0.517577\n",
      "  validation accuracy:\t\t82.06 %\n",
      "Epoch 57 of 300 took 1.141s\n",
      "  training loss:\t\t0.036567\n",
      "  validation loss:\t\t0.535759\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 58 of 300 took 1.140s\n",
      "  training loss:\t\t0.037740\n",
      "  validation loss:\t\t0.534401\n",
      "  validation accuracy:\t\t82.39 %\n",
      "Epoch 59 of 300 took 1.141s\n",
      "  training loss:\t\t0.030703\n",
      "  validation loss:\t\t0.543045\n",
      "  validation accuracy:\t\t82.19 %\n",
      "Epoch 60 of 300 took 1.140s\n",
      "  training loss:\t\t0.038145\n",
      "  validation loss:\t\t0.552828\n",
      "  validation accuracy:\t\t82.13 %\n",
      "Epoch 61 of 300 took 1.141s\n",
      "  training loss:\t\t0.033679\n",
      "  validation loss:\t\t0.541930\n",
      "  validation accuracy:\t\t82.39 %\n",
      "Epoch 62 of 300 took 1.140s\n",
      "  training loss:\t\t0.028740\n",
      "  validation loss:\t\t0.544638\n",
      "  validation accuracy:\t\t81.81 %\n",
      "Epoch 63 of 300 took 1.140s\n",
      "  training loss:\t\t0.033271\n",
      "  validation loss:\t\t0.554336\n",
      "  validation accuracy:\t\t82.39 %\n",
      "Epoch 64 of 300 took 1.140s\n",
      "  training loss:\t\t0.030191\n",
      "  validation loss:\t\t0.590193\n",
      "  validation accuracy:\t\t82.13 %\n",
      "Epoch 65 of 300 took 1.140s\n",
      "  training loss:\t\t0.026835\n",
      "  validation loss:\t\t0.581361\n",
      "  validation accuracy:\t\t81.87 %\n",
      "Epoch 66 of 300 took 1.140s\n",
      "  training loss:\t\t0.030881\n",
      "  validation loss:\t\t0.589313\n",
      "  validation accuracy:\t\t81.48 %\n",
      "Epoch 67 of 300 took 1.140s\n",
      "  training loss:\t\t0.025670\n",
      "  validation loss:\t\t0.581064\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 68 of 300 took 1.140s\n",
      "  training loss:\t\t0.027462\n",
      "  validation loss:\t\t0.581077\n",
      "  validation accuracy:\t\t82.00 %\n",
      "Epoch 69 of 300 took 1.140s\n",
      "  training loss:\t\t0.027123\n",
      "  validation loss:\t\t0.570827\n",
      "  validation accuracy:\t\t81.61 %\n",
      "Epoch 70 of 300 took 1.140s\n",
      "  training loss:\t\t0.023857\n",
      "  validation loss:\t\t0.614764\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 71 of 300 took 1.141s\n",
      "  training loss:\t\t0.023511\n",
      "  validation loss:\t\t0.594968\n",
      "  validation accuracy:\t\t81.16 %\n",
      "Epoch 72 of 300 took 1.140s\n",
      "  training loss:\t\t0.021528\n",
      "  validation loss:\t\t0.583156\n",
      "  validation accuracy:\t\t82.00 %\n",
      "Epoch 73 of 300 took 1.141s\n",
      "  training loss:\t\t0.022307\n",
      "  validation loss:\t\t0.592214\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 74 of 300 took 1.140s\n",
      "  training loss:\t\t0.022322\n",
      "  validation loss:\t\t0.608963\n",
      "  validation accuracy:\t\t81.48 %\n",
      "Epoch 75 of 300 took 1.141s\n",
      "  training loss:\t\t0.021475\n",
      "  validation loss:\t\t0.599463\n",
      "  validation accuracy:\t\t81.68 %\n",
      "Epoch 76 of 300 took 1.140s\n",
      "  training loss:\t\t0.021500\n",
      "  validation loss:\t\t0.649591\n",
      "  validation accuracy:\t\t80.71 %\n",
      "Epoch 77 of 300 took 1.140s\n",
      "  training loss:\t\t0.019623\n",
      "  validation loss:\t\t0.623264\n",
      "  validation accuracy:\t\t81.23 %\n",
      "Epoch 78 of 300 took 1.140s\n",
      "  training loss:\t\t0.019513\n",
      "  validation loss:\t\t0.620160\n",
      "  validation accuracy:\t\t81.68 %\n",
      "Epoch 79 of 300 took 1.140s\n",
      "  training loss:\t\t0.018266\n",
      "  validation loss:\t\t0.628305\n",
      "  validation accuracy:\t\t82.00 %\n",
      "Epoch 80 of 300 took 1.140s\n",
      "  training loss:\t\t0.025729\n",
      "  validation loss:\t\t0.592687\n",
      "  validation accuracy:\t\t81.29 %\n",
      "Epoch 81 of 300 took 1.141s\n",
      "  training loss:\t\t0.017944\n",
      "  validation loss:\t\t0.623575\n",
      "  validation accuracy:\t\t81.68 %\n",
      "Epoch 82 of 300 took 1.140s\n",
      "  training loss:\t\t0.020086\n",
      "  validation loss:\t\t0.617886\n",
      "  validation accuracy:\t\t81.68 %\n",
      "Epoch 83 of 300 took 1.140s\n",
      "  training loss:\t\t0.019977\n",
      "  validation loss:\t\t0.614655\n",
      "  validation accuracy:\t\t81.48 %\n",
      "Epoch 84 of 300 took 1.141s\n",
      "  training loss:\t\t0.020889\n",
      "  validation loss:\t\t0.615164\n",
      "  validation accuracy:\t\t81.03 %\n",
      "Epoch 85 of 300 took 1.140s\n",
      "  training loss:\t\t0.020062\n",
      "  validation loss:\t\t0.620686\n",
      "  validation accuracy:\t\t81.81 %\n",
      "Epoch 86 of 300 took 1.140s\n",
      "  training loss:\t\t0.015294\n",
      "  validation loss:\t\t0.638639\n",
      "  validation accuracy:\t\t82.06 %\n",
      "Epoch 87 of 300 took 1.140s\n",
      "  training loss:\t\t0.017037\n",
      "  validation loss:\t\t0.620384\n",
      "  validation accuracy:\t\t81.81 %\n",
      "Epoch 88 of 300 took 1.140s\n",
      "  training loss:\t\t0.022480\n",
      "  validation loss:\t\t0.613028\n",
      "  validation accuracy:\t\t81.87 %\n",
      "Epoch 89 of 300 took 1.141s\n",
      "  training loss:\t\t0.016872\n",
      "  validation loss:\t\t0.675145\n",
      "  validation accuracy:\t\t80.71 %\n",
      "Epoch 90 of 300 took 1.140s\n",
      "  training loss:\t\t0.022439\n",
      "  validation loss:\t\t0.622686\n",
      "  validation accuracy:\t\t81.16 %\n",
      "Epoch 91 of 300 took 1.140s\n",
      "  training loss:\t\t0.017446\n",
      "  validation loss:\t\t0.680343\n",
      "  validation accuracy:\t\t80.71 %\n",
      "Epoch 92 of 300 took 1.141s\n",
      "  training loss:\t\t0.014522\n",
      "  validation loss:\t\t0.703723\n",
      "  validation accuracy:\t\t80.65 %\n",
      "Epoch 93 of 300 took 1.140s\n",
      "  training loss:\t\t0.015735\n",
      "  validation loss:\t\t0.656081\n",
      "  validation accuracy:\t\t81.94 %\n",
      "Epoch 94 of 300 took 1.140s\n",
      "  training loss:\t\t0.017664\n",
      "  validation loss:\t\t0.646780\n",
      "  validation accuracy:\t\t81.87 %\n",
      "Epoch 95 of 300 took 1.142s\n",
      "  training loss:\t\t0.017522\n",
      "  validation loss:\t\t0.635317\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 96 of 300 took 1.141s\n",
      "  training loss:\t\t0.016310\n",
      "  validation loss:\t\t0.647552\n",
      "  validation accuracy:\t\t81.61 %\n",
      "Epoch 97 of 300 took 1.140s\n",
      "  training loss:\t\t0.015383\n",
      "  validation loss:\t\t0.677397\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 98 of 300 took 1.140s\n",
      "  training loss:\t\t0.018431\n",
      "  validation loss:\t\t0.649118\n",
      "  validation accuracy:\t\t81.87 %\n",
      "Epoch 99 of 300 took 1.140s\n",
      "  training loss:\t\t0.016161\n",
      "  validation loss:\t\t0.679093\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 100 of 300 took 1.140s\n",
      "  training loss:\t\t0.013202\n",
      "  validation loss:\t\t0.666733\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 101 of 300 took 1.140s\n",
      "  training loss:\t\t0.014260\n",
      "  validation loss:\t\t0.696114\n",
      "  validation accuracy:\t\t80.97 %\n",
      "Epoch 102 of 300 took 1.140s\n",
      "  training loss:\t\t0.015450\n",
      "  validation loss:\t\t0.702395\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 103 of 300 took 1.140s\n",
      "  training loss:\t\t0.013229\n",
      "  validation loss:\t\t0.661284\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 104 of 300 took 1.140s\n",
      "  training loss:\t\t0.015552\n",
      "  validation loss:\t\t0.679817\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 105 of 300 took 1.140s\n",
      "  training loss:\t\t0.014555\n",
      "  validation loss:\t\t0.675612\n",
      "  validation accuracy:\t\t82.13 %\n",
      "Epoch 106 of 300 took 1.140s\n",
      "  training loss:\t\t0.009360\n",
      "  validation loss:\t\t0.685090\n",
      "  validation accuracy:\t\t82.00 %\n",
      "Epoch 107 of 300 took 1.140s\n",
      "  training loss:\t\t0.015511\n",
      "  validation loss:\t\t0.678497\n",
      "  validation accuracy:\t\t81.94 %\n",
      "Epoch 108 of 300 took 1.140s\n",
      "  training loss:\t\t0.015873\n",
      "  validation loss:\t\t0.687504\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 109 of 300 took 1.140s\n",
      "  training loss:\t\t0.017337\n",
      "  validation loss:\t\t0.684958\n",
      "  validation accuracy:\t\t81.42 %\n",
      "Epoch 110 of 300 took 1.140s\n",
      "  training loss:\t\t0.012719\n",
      "  validation loss:\t\t0.694975\n",
      "  validation accuracy:\t\t81.81 %\n",
      "Epoch 111 of 300 took 1.140s\n",
      "  training loss:\t\t0.014742\n",
      "  validation loss:\t\t0.677981\n",
      "  validation accuracy:\t\t81.29 %\n",
      "Epoch 112 of 300 took 1.140s\n",
      "  training loss:\t\t0.014261\n",
      "  validation loss:\t\t0.713942\n",
      "  validation accuracy:\t\t81.68 %\n",
      "Epoch 113 of 300 took 1.140s\n",
      "  training loss:\t\t0.016021\n",
      "  validation loss:\t\t0.681751\n",
      "  validation accuracy:\t\t81.48 %\n",
      "Epoch 114 of 300 took 1.140s\n",
      "  training loss:\t\t0.010665\n",
      "  validation loss:\t\t0.686555\n",
      "  validation accuracy:\t\t81.87 %\n",
      "Epoch 115 of 300 took 1.140s\n",
      "  training loss:\t\t0.010479\n",
      "  validation loss:\t\t0.729517\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 116 of 300 took 1.142s\n",
      "  training loss:\t\t0.009918\n",
      "  validation loss:\t\t0.707580\n",
      "  validation accuracy:\t\t81.61 %\n",
      "Epoch 117 of 300 took 1.140s\n",
      "  training loss:\t\t0.011219\n",
      "  validation loss:\t\t0.730926\n",
      "  validation accuracy:\t\t81.16 %\n",
      "Epoch 118 of 300 took 1.140s\n",
      "  training loss:\t\t0.015815\n",
      "  validation loss:\t\t0.708983\n",
      "  validation accuracy:\t\t80.71 %\n",
      "Epoch 119 of 300 took 1.140s\n",
      "  training loss:\t\t0.010468\n",
      "  validation loss:\t\t0.722811\n",
      "  validation accuracy:\t\t81.94 %\n",
      "Epoch 120 of 300 took 1.140s\n",
      "  training loss:\t\t0.017264\n",
      "  validation loss:\t\t0.695298\n",
      "  validation accuracy:\t\t82.06 %\n",
      "Epoch 121 of 300 took 1.140s\n",
      "  training loss:\t\t0.010017\n",
      "  validation loss:\t\t0.715675\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 122 of 300 took 1.140s\n",
      "  training loss:\t\t0.013555\n",
      "  validation loss:\t\t0.713200\n",
      "  validation accuracy:\t\t81.81 %\n",
      "Epoch 123 of 300 took 1.140s\n",
      "  training loss:\t\t0.012483\n",
      "  validation loss:\t\t0.715563\n",
      "  validation accuracy:\t\t81.48 %\n",
      "Epoch 124 of 300 took 1.140s\n",
      "  training loss:\t\t0.009700\n",
      "  validation loss:\t\t0.709188\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 125 of 300 took 1.140s\n",
      "  training loss:\t\t0.014483\n",
      "  validation loss:\t\t0.726400\n",
      "  validation accuracy:\t\t81.23 %\n",
      "Epoch 126 of 300 took 1.140s\n",
      "  training loss:\t\t0.013168\n",
      "  validation loss:\t\t0.704321\n",
      "  validation accuracy:\t\t81.48 %\n",
      "Epoch 127 of 300 took 1.140s\n",
      "  training loss:\t\t0.012951\n",
      "  validation loss:\t\t0.708075\n",
      "  validation accuracy:\t\t81.81 %\n",
      "Epoch 128 of 300 took 1.140s\n",
      "  training loss:\t\t0.012241\n",
      "  validation loss:\t\t0.729320\n",
      "  validation accuracy:\t\t81.61 %\n",
      "Epoch 129 of 300 took 1.140s\n",
      "  training loss:\t\t0.009431\n",
      "  validation loss:\t\t0.762116\n",
      "  validation accuracy:\t\t80.71 %\n",
      "Epoch 130 of 300 took 1.140s\n",
      "  training loss:\t\t0.011064\n",
      "  validation loss:\t\t0.735912\n",
      "  validation accuracy:\t\t81.23 %\n",
      "Epoch 131 of 300 took 1.140s\n",
      "  training loss:\t\t0.011764\n",
      "  validation loss:\t\t0.751129\n",
      "  validation accuracy:\t\t81.29 %\n",
      "Epoch 132 of 300 took 1.140s\n",
      "  training loss:\t\t0.013456\n",
      "  validation loss:\t\t0.742791\n",
      "  validation accuracy:\t\t80.84 %\n",
      "Epoch 133 of 300 took 1.140s\n",
      "  training loss:\t\t0.013170\n",
      "  validation loss:\t\t0.740417\n",
      "  validation accuracy:\t\t81.16 %\n",
      "Epoch 134 of 300 took 1.141s\n",
      "  training loss:\t\t0.010601\n",
      "  validation loss:\t\t0.730364\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 135 of 300 took 1.140s\n",
      "  training loss:\t\t0.014671\n",
      "  validation loss:\t\t0.803676\n",
      "  validation accuracy:\t\t80.84 %\n",
      "Epoch 136 of 300 took 1.140s\n",
      "  training loss:\t\t0.013046\n",
      "  validation loss:\t\t0.716061\n",
      "  validation accuracy:\t\t81.81 %\n",
      "Epoch 137 of 300 took 1.140s\n",
      "  training loss:\t\t0.010651\n",
      "  validation loss:\t\t0.778239\n",
      "  validation accuracy:\t\t80.71 %\n",
      "Epoch 138 of 300 took 1.140s\n",
      "  training loss:\t\t0.013184\n",
      "  validation loss:\t\t0.745298\n",
      "  validation accuracy:\t\t81.16 %\n",
      "Epoch 139 of 300 took 1.140s\n",
      "  training loss:\t\t0.012534\n",
      "  validation loss:\t\t0.757058\n",
      "  validation accuracy:\t\t81.48 %\n",
      "Epoch 140 of 300 took 1.141s\n",
      "  training loss:\t\t0.012634\n",
      "  validation loss:\t\t0.737904\n",
      "  validation accuracy:\t\t81.61 %\n",
      "Epoch 141 of 300 took 1.140s\n",
      "  training loss:\t\t0.009274\n",
      "  validation loss:\t\t0.780320\n",
      "  validation accuracy:\t\t81.29 %\n",
      "Epoch 142 of 300 took 1.140s\n",
      "  training loss:\t\t0.009218\n",
      "  validation loss:\t\t0.747892\n",
      "  validation accuracy:\t\t82.06 %\n",
      "Epoch 143 of 300 took 1.140s\n",
      "  training loss:\t\t0.010280\n",
      "  validation loss:\t\t0.816081\n",
      "  validation accuracy:\t\t80.90 %\n",
      "Epoch 144 of 300 took 1.140s\n",
      "  training loss:\t\t0.011455\n",
      "  validation loss:\t\t0.770856\n",
      "  validation accuracy:\t\t81.23 %\n",
      "Epoch 145 of 300 took 1.140s\n",
      "  training loss:\t\t0.007849\n",
      "  validation loss:\t\t0.734630\n",
      "  validation accuracy:\t\t81.29 %\n",
      "Epoch 146 of 300 took 1.140s\n",
      "  training loss:\t\t0.010080\n",
      "  validation loss:\t\t0.734262\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 147 of 300 took 1.140s\n",
      "  training loss:\t\t0.009690\n",
      "  validation loss:\t\t0.745135\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 148 of 300 took 1.140s\n",
      "  training loss:\t\t0.010055\n",
      "  validation loss:\t\t0.755852\n",
      "  validation accuracy:\t\t81.68 %\n",
      "Epoch 149 of 300 took 1.141s\n",
      "  training loss:\t\t0.010647\n",
      "  validation loss:\t\t0.772251\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 150 of 300 took 1.140s\n",
      "  training loss:\t\t0.010413\n",
      "  validation loss:\t\t0.738704\n",
      "  validation accuracy:\t\t81.81 %\n",
      "Epoch 151 of 300 took 1.140s\n",
      "  training loss:\t\t0.014736\n",
      "  validation loss:\t\t0.740903\n",
      "  validation accuracy:\t\t82.00 %\n",
      "Epoch 152 of 300 took 1.140s\n",
      "  training loss:\t\t0.008433\n",
      "  validation loss:\t\t0.769097\n",
      "  validation accuracy:\t\t81.10 %\n",
      "Epoch 153 of 300 took 1.140s\n",
      "  training loss:\t\t0.013046\n",
      "  validation loss:\t\t0.747543\n",
      "  validation accuracy:\t\t80.90 %\n",
      "Epoch 154 of 300 took 1.140s\n",
      "  training loss:\t\t0.011251\n",
      "  validation loss:\t\t0.735841\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 155 of 300 took 1.140s\n",
      "  training loss:\t\t0.011770\n",
      "  validation loss:\t\t0.747516\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 156 of 300 took 1.140s\n",
      "  training loss:\t\t0.012892\n",
      "  validation loss:\t\t0.769031\n",
      "  validation accuracy:\t\t80.65 %\n",
      "Epoch 157 of 300 took 1.139s\n",
      "  training loss:\t\t0.010561\n",
      "  validation loss:\t\t0.754283\n",
      "  validation accuracy:\t\t81.16 %\n",
      "Epoch 158 of 300 took 1.141s\n",
      "  training loss:\t\t0.009257\n",
      "  validation loss:\t\t0.739120\n",
      "  validation accuracy:\t\t81.23 %\n",
      "Epoch 159 of 300 took 1.140s\n",
      "  training loss:\t\t0.013616\n",
      "  validation loss:\t\t0.728310\n",
      "  validation accuracy:\t\t81.68 %\n",
      "Epoch 160 of 300 took 1.140s\n",
      "  training loss:\t\t0.009745\n",
      "  validation loss:\t\t0.762059\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 161 of 300 took 1.141s\n",
      "  training loss:\t\t0.009472\n",
      "  validation loss:\t\t0.745952\n",
      "  validation accuracy:\t\t82.00 %\n",
      "Epoch 162 of 300 took 1.140s\n",
      "  training loss:\t\t0.006673\n",
      "  validation loss:\t\t0.750983\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 163 of 300 took 1.140s\n",
      "  training loss:\t\t0.009972\n",
      "  validation loss:\t\t0.748115\n",
      "  validation accuracy:\t\t81.42 %\n",
      "Epoch 164 of 300 took 1.140s\n",
      "  training loss:\t\t0.013368\n",
      "  validation loss:\t\t0.751215\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 165 of 300 took 1.140s\n",
      "  training loss:\t\t0.008527\n",
      "  validation loss:\t\t0.773977\n",
      "  validation accuracy:\t\t81.81 %\n",
      "Epoch 166 of 300 took 1.141s\n",
      "  training loss:\t\t0.008375\n",
      "  validation loss:\t\t0.795699\n",
      "  validation accuracy:\t\t81.03 %\n",
      "Epoch 167 of 300 took 1.140s\n",
      "  training loss:\t\t0.008689\n",
      "  validation loss:\t\t0.769758\n",
      "  validation accuracy:\t\t81.03 %\n",
      "Epoch 168 of 300 took 1.140s\n",
      "  training loss:\t\t0.012114\n",
      "  validation loss:\t\t0.748235\n",
      "  validation accuracy:\t\t81.29 %\n",
      "Epoch 169 of 300 took 1.141s\n",
      "  training loss:\t\t0.011007\n",
      "  validation loss:\t\t0.735531\n",
      "  validation accuracy:\t\t81.68 %\n",
      "Epoch 170 of 300 took 1.139s\n",
      "  training loss:\t\t0.011054\n",
      "  validation loss:\t\t0.775806\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 171 of 300 took 1.140s\n",
      "  training loss:\t\t0.008127\n",
      "  validation loss:\t\t0.782569\n",
      "  validation accuracy:\t\t81.29 %\n",
      "Epoch 172 of 300 took 1.140s\n",
      "  training loss:\t\t0.007361\n",
      "  validation loss:\t\t0.781533\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 173 of 300 took 1.140s\n",
      "  training loss:\t\t0.011638\n",
      "  validation loss:\t\t0.760935\n",
      "  validation accuracy:\t\t81.68 %\n",
      "Epoch 174 of 300 took 1.140s\n",
      "  training loss:\t\t0.009431\n",
      "  validation loss:\t\t0.781565\n",
      "  validation accuracy:\t\t81.03 %\n",
      "Epoch 175 of 300 took 1.140s\n",
      "  training loss:\t\t0.007993\n",
      "  validation loss:\t\t0.762251\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 176 of 300 took 1.140s\n",
      "  training loss:\t\t0.010042\n",
      "  validation loss:\t\t0.749022\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 177 of 300 took 1.140s\n",
      "  training loss:\t\t0.010118\n",
      "  validation loss:\t\t0.774650\n",
      "  validation accuracy:\t\t80.77 %\n",
      "Epoch 178 of 300 took 1.140s\n",
      "  training loss:\t\t0.009061\n",
      "  validation loss:\t\t0.795003\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 179 of 300 took 1.140s\n",
      "  training loss:\t\t0.008139\n",
      "  validation loss:\t\t0.785987\n",
      "  validation accuracy:\t\t81.61 %\n",
      "Epoch 180 of 300 took 1.140s\n",
      "  training loss:\t\t0.006464\n",
      "  validation loss:\t\t0.795733\n",
      "  validation accuracy:\t\t81.23 %\n",
      "Epoch 181 of 300 took 1.140s\n",
      "  training loss:\t\t0.007426\n",
      "  validation loss:\t\t0.810014\n",
      "  validation accuracy:\t\t81.23 %\n",
      "Epoch 182 of 300 took 1.140s\n",
      "  training loss:\t\t0.008043\n",
      "  validation loss:\t\t0.794468\n",
      "  validation accuracy:\t\t81.29 %\n",
      "Epoch 183 of 300 took 1.140s\n",
      "  training loss:\t\t0.006360\n",
      "  validation loss:\t\t0.841606\n",
      "  validation accuracy:\t\t81.42 %\n",
      "Epoch 184 of 300 took 1.140s\n",
      "  training loss:\t\t0.010777\n",
      "  validation loss:\t\t0.769233\n",
      "  validation accuracy:\t\t81.81 %\n",
      "Epoch 185 of 300 took 1.140s\n",
      "  training loss:\t\t0.008343\n",
      "  validation loss:\t\t0.788478\n",
      "  validation accuracy:\t\t81.81 %\n",
      "Epoch 186 of 300 took 1.141s\n",
      "  training loss:\t\t0.009524\n",
      "  validation loss:\t\t0.780693\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 187 of 300 took 1.140s\n",
      "  training loss:\t\t0.008683\n",
      "  validation loss:\t\t0.869037\n",
      "  validation accuracy:\t\t79.94 %\n",
      "Epoch 188 of 300 took 1.140s\n",
      "  training loss:\t\t0.009659\n",
      "  validation loss:\t\t0.781095\n",
      "  validation accuracy:\t\t81.68 %\n",
      "Epoch 189 of 300 took 1.141s\n",
      "  training loss:\t\t0.008069\n",
      "  validation loss:\t\t0.834483\n",
      "  validation accuracy:\t\t81.29 %\n",
      "Epoch 190 of 300 took 1.140s\n",
      "  training loss:\t\t0.010902\n",
      "  validation loss:\t\t0.837873\n",
      "  validation accuracy:\t\t80.58 %\n",
      "Epoch 191 of 300 took 1.140s\n",
      "  training loss:\t\t0.010373\n",
      "  validation loss:\t\t0.772154\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 192 of 300 took 1.140s\n",
      "  training loss:\t\t0.009103\n",
      "  validation loss:\t\t0.764802\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 193 of 300 took 1.140s\n",
      "  training loss:\t\t0.007943\n",
      "  validation loss:\t\t0.777327\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 194 of 300 took 1.139s\n",
      "  training loss:\t\t0.006360\n",
      "  validation loss:\t\t0.810089\n",
      "  validation accuracy:\t\t81.68 %\n",
      "Epoch 195 of 300 took 1.141s\n",
      "  training loss:\t\t0.008700\n",
      "  validation loss:\t\t0.805128\n",
      "  validation accuracy:\t\t81.29 %\n",
      "Epoch 196 of 300 took 1.140s\n",
      "  training loss:\t\t0.005954\n",
      "  validation loss:\t\t0.818785\n",
      "  validation accuracy:\t\t81.61 %\n",
      "Epoch 197 of 300 took 1.140s\n",
      "  training loss:\t\t0.009462\n",
      "  validation loss:\t\t0.793500\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 198 of 300 took 1.140s\n",
      "  training loss:\t\t0.009669\n",
      "  validation loss:\t\t0.804276\n",
      "  validation accuracy:\t\t80.65 %\n",
      "Epoch 199 of 300 took 1.140s\n",
      "  training loss:\t\t0.007333\n",
      "  validation loss:\t\t0.798096\n",
      "  validation accuracy:\t\t81.48 %\n",
      "Epoch 200 of 300 took 1.141s\n",
      "  training loss:\t\t0.008786\n",
      "  validation loss:\t\t0.779929\n",
      "  validation accuracy:\t\t81.61 %\n",
      "Epoch 201 of 300 took 1.140s\n",
      "  training loss:\t\t0.007858\n",
      "  validation loss:\t\t0.802334\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 202 of 300 took 1.140s\n",
      "  training loss:\t\t0.007453\n",
      "  validation loss:\t\t0.810833\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 203 of 300 took 1.140s\n",
      "  training loss:\t\t0.010799\n",
      "  validation loss:\t\t0.789318\n",
      "  validation accuracy:\t\t81.48 %\n",
      "Epoch 204 of 300 took 1.140s\n",
      "  training loss:\t\t0.007895\n",
      "  validation loss:\t\t0.812345\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 205 of 300 took 1.140s\n",
      "  training loss:\t\t0.007847\n",
      "  validation loss:\t\t0.827746\n",
      "  validation accuracy:\t\t81.03 %\n",
      "Epoch 206 of 300 took 1.140s\n",
      "  training loss:\t\t0.009487\n",
      "  validation loss:\t\t0.807993\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 207 of 300 took 1.140s\n",
      "  training loss:\t\t0.008367\n",
      "  validation loss:\t\t0.791075\n",
      "  validation accuracy:\t\t81.23 %\n",
      "Epoch 208 of 300 took 1.140s\n",
      "  training loss:\t\t0.007399\n",
      "  validation loss:\t\t0.878910\n",
      "  validation accuracy:\t\t80.58 %\n",
      "Epoch 209 of 300 took 1.140s\n",
      "  training loss:\t\t0.007492\n",
      "  validation loss:\t\t0.803516\n",
      "  validation accuracy:\t\t81.81 %\n",
      "Epoch 210 of 300 took 1.140s\n",
      "  training loss:\t\t0.007151\n",
      "  validation loss:\t\t0.829664\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 211 of 300 took 1.140s\n",
      "  training loss:\t\t0.009836\n",
      "  validation loss:\t\t0.792188\n",
      "  validation accuracy:\t\t81.42 %\n",
      "Epoch 212 of 300 took 1.140s\n",
      "  training loss:\t\t0.005708\n",
      "  validation loss:\t\t0.838589\n",
      "  validation accuracy:\t\t81.16 %\n",
      "Epoch 213 of 300 took 1.140s\n",
      "  training loss:\t\t0.009218\n",
      "  validation loss:\t\t0.888759\n",
      "  validation accuracy:\t\t80.19 %\n",
      "Epoch 214 of 300 took 1.140s\n",
      "  training loss:\t\t0.005574\n",
      "  validation loss:\t\t0.824448\n",
      "  validation accuracy:\t\t81.10 %\n",
      "Epoch 215 of 300 took 1.140s\n",
      "  training loss:\t\t0.007120\n",
      "  validation loss:\t\t0.798889\n",
      "  validation accuracy:\t\t81.23 %\n",
      "Epoch 216 of 300 took 1.140s\n",
      "  training loss:\t\t0.006082\n",
      "  validation loss:\t\t0.846891\n",
      "  validation accuracy:\t\t81.42 %\n",
      "Epoch 217 of 300 took 1.140s\n",
      "  training loss:\t\t0.007823\n",
      "  validation loss:\t\t0.810202\n",
      "  validation accuracy:\t\t81.48 %\n",
      "Epoch 218 of 300 took 1.140s\n",
      "  training loss:\t\t0.007427\n",
      "  validation loss:\t\t0.851343\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 219 of 300 took 1.140s\n",
      "  training loss:\t\t0.006790\n",
      "  validation loss:\t\t0.816752\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 220 of 300 took 1.140s\n",
      "  training loss:\t\t0.007063\n",
      "  validation loss:\t\t0.812286\n",
      "  validation accuracy:\t\t81.61 %\n",
      "Epoch 221 of 300 took 1.141s\n",
      "  training loss:\t\t0.007223\n",
      "  validation loss:\t\t0.838128\n",
      "  validation accuracy:\t\t81.61 %\n",
      "Epoch 222 of 300 took 1.140s\n",
      "  training loss:\t\t0.007866\n",
      "  validation loss:\t\t0.819901\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 223 of 300 took 1.140s\n",
      "  training loss:\t\t0.008575\n",
      "  validation loss:\t\t0.778789\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 224 of 300 took 1.140s\n",
      "  training loss:\t\t0.007705\n",
      "  validation loss:\t\t0.841122\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 225 of 300 took 1.140s\n",
      "  training loss:\t\t0.006006\n",
      "  validation loss:\t\t0.869674\n",
      "  validation accuracy:\t\t80.71 %\n",
      "Epoch 226 of 300 took 1.140s\n",
      "  training loss:\t\t0.007703\n",
      "  validation loss:\t\t0.845421\n",
      "  validation accuracy:\t\t81.03 %\n",
      "Epoch 227 of 300 took 1.140s\n",
      "  training loss:\t\t0.008127\n",
      "  validation loss:\t\t0.817521\n",
      "  validation accuracy:\t\t81.61 %\n",
      "Epoch 228 of 300 took 1.140s\n",
      "  training loss:\t\t0.007462\n",
      "  validation loss:\t\t0.817557\n",
      "  validation accuracy:\t\t80.84 %\n",
      "Epoch 229 of 300 took 1.140s\n",
      "  training loss:\t\t0.008257\n",
      "  validation loss:\t\t0.802690\n",
      "  validation accuracy:\t\t81.94 %\n",
      "Epoch 230 of 300 took 1.141s\n",
      "  training loss:\t\t0.005689\n",
      "  validation loss:\t\t0.815331\n",
      "  validation accuracy:\t\t81.16 %\n",
      "Epoch 231 of 300 took 1.141s\n",
      "  training loss:\t\t0.008624\n",
      "  validation loss:\t\t0.809368\n",
      "  validation accuracy:\t\t80.84 %\n",
      "Epoch 232 of 300 took 1.140s\n",
      "  training loss:\t\t0.004197\n",
      "  validation loss:\t\t0.903266\n",
      "  validation accuracy:\t\t79.94 %\n",
      "Epoch 233 of 300 took 1.139s\n",
      "  training loss:\t\t0.007326\n",
      "  validation loss:\t\t0.872403\n",
      "  validation accuracy:\t\t81.10 %\n",
      "Epoch 234 of 300 took 1.140s\n",
      "  training loss:\t\t0.007247\n",
      "  validation loss:\t\t0.840925\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 235 of 300 took 1.140s\n",
      "  training loss:\t\t0.008376\n",
      "  validation loss:\t\t0.827344\n",
      "  validation accuracy:\t\t81.42 %\n",
      "Epoch 236 of 300 took 1.140s\n",
      "  training loss:\t\t0.008352\n",
      "  validation loss:\t\t0.849083\n",
      "  validation accuracy:\t\t81.29 %\n",
      "Epoch 237 of 300 took 1.140s\n",
      "  training loss:\t\t0.006432\n",
      "  validation loss:\t\t0.838363\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 238 of 300 took 1.140s\n",
      "  training loss:\t\t0.006001\n",
      "  validation loss:\t\t0.830220\n",
      "  validation accuracy:\t\t81.48 %\n",
      "Epoch 239 of 300 took 1.141s\n",
      "  training loss:\t\t0.007051\n",
      "  validation loss:\t\t0.795252\n",
      "  validation accuracy:\t\t81.48 %\n",
      "Epoch 240 of 300 took 1.140s\n",
      "  training loss:\t\t0.006886\n",
      "  validation loss:\t\t0.814175\n",
      "  validation accuracy:\t\t81.42 %\n",
      "Epoch 241 of 300 took 1.139s\n",
      "  training loss:\t\t0.008059\n",
      "  validation loss:\t\t0.826553\n",
      "  validation accuracy:\t\t81.48 %\n",
      "Epoch 242 of 300 took 1.140s\n",
      "  training loss:\t\t0.006336\n",
      "  validation loss:\t\t0.825512\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 243 of 300 took 1.140s\n",
      "  training loss:\t\t0.005618\n",
      "  validation loss:\t\t0.840317\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 244 of 300 took 1.141s\n",
      "  training loss:\t\t0.007117\n",
      "  validation loss:\t\t0.821529\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 245 of 300 took 1.140s\n",
      "  training loss:\t\t0.008546\n",
      "  validation loss:\t\t0.843255\n",
      "  validation accuracy:\t\t81.03 %\n",
      "Epoch 246 of 300 took 1.140s\n",
      "  training loss:\t\t0.006604\n",
      "  validation loss:\t\t0.831607\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 247 of 300 took 1.140s\n",
      "  training loss:\t\t0.008710\n",
      "  validation loss:\t\t0.848252\n",
      "  validation accuracy:\t\t81.23 %\n",
      "Epoch 248 of 300 took 1.140s\n",
      "  training loss:\t\t0.006668\n",
      "  validation loss:\t\t0.875108\n",
      "  validation accuracy:\t\t80.45 %\n",
      "Epoch 249 of 300 took 1.140s\n",
      "  training loss:\t\t0.006343\n",
      "  validation loss:\t\t0.838243\n",
      "  validation accuracy:\t\t81.42 %\n",
      "Epoch 250 of 300 took 1.141s\n",
      "  training loss:\t\t0.006001\n",
      "  validation loss:\t\t0.870291\n",
      "  validation accuracy:\t\t81.16 %\n",
      "Epoch 251 of 300 took 1.140s\n",
      "  training loss:\t\t0.007085\n",
      "  validation loss:\t\t0.927683\n",
      "  validation accuracy:\t\t80.71 %\n",
      "Epoch 252 of 300 took 1.140s\n",
      "  training loss:\t\t0.007187\n",
      "  validation loss:\t\t0.817748\n",
      "  validation accuracy:\t\t81.42 %\n",
      "Epoch 253 of 300 took 1.140s\n",
      "  training loss:\t\t0.005442\n",
      "  validation loss:\t\t0.840545\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 254 of 300 took 1.140s\n",
      "  training loss:\t\t0.005613\n",
      "  validation loss:\t\t0.873995\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 255 of 300 took 1.140s\n",
      "  training loss:\t\t0.007121\n",
      "  validation loss:\t\t0.830373\n",
      "  validation accuracy:\t\t81.42 %\n",
      "Epoch 256 of 300 took 1.140s\n",
      "  training loss:\t\t0.006619\n",
      "  validation loss:\t\t0.832669\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 257 of 300 took 1.140s\n",
      "  training loss:\t\t0.005245\n",
      "  validation loss:\t\t0.870791\n",
      "  validation accuracy:\t\t81.23 %\n",
      "Epoch 258 of 300 took 1.140s\n",
      "  training loss:\t\t0.006330\n",
      "  validation loss:\t\t0.850831\n",
      "  validation accuracy:\t\t81.61 %\n",
      "Epoch 259 of 300 took 1.140s\n",
      "  training loss:\t\t0.007523\n",
      "  validation loss:\t\t0.906479\n",
      "  validation accuracy:\t\t80.26 %\n",
      "Epoch 260 of 300 took 1.140s\n",
      "  training loss:\t\t0.006890\n",
      "  validation loss:\t\t0.865148\n",
      "  validation accuracy:\t\t80.97 %\n",
      "Epoch 261 of 300 took 1.140s\n",
      "  training loss:\t\t0.006462\n",
      "  validation loss:\t\t0.847770\n",
      "  validation accuracy:\t\t81.48 %\n",
      "Epoch 262 of 300 took 1.140s\n",
      "  training loss:\t\t0.008517\n",
      "  validation loss:\t\t0.863876\n",
      "  validation accuracy:\t\t80.84 %\n",
      "Epoch 263 of 300 took 1.140s\n",
      "  training loss:\t\t0.005432\n",
      "  validation loss:\t\t0.839059\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 264 of 300 took 1.140s\n",
      "  training loss:\t\t0.006242\n",
      "  validation loss:\t\t0.854559\n",
      "  validation accuracy:\t\t81.10 %\n",
      "Epoch 265 of 300 took 1.140s\n",
      "  training loss:\t\t0.006225\n",
      "  validation loss:\t\t0.842385\n",
      "  validation accuracy:\t\t81.42 %\n",
      "Epoch 266 of 300 took 1.141s\n",
      "  training loss:\t\t0.005756\n",
      "  validation loss:\t\t0.863563\n",
      "  validation accuracy:\t\t81.29 %\n",
      "Epoch 267 of 300 took 1.140s\n",
      "  training loss:\t\t0.006818\n",
      "  validation loss:\t\t0.868868\n",
      "  validation accuracy:\t\t81.03 %\n",
      "Epoch 268 of 300 took 1.140s\n",
      "  training loss:\t\t0.005296\n",
      "  validation loss:\t\t0.842519\n",
      "  validation accuracy:\t\t81.42 %\n",
      "Epoch 269 of 300 took 1.140s\n",
      "  training loss:\t\t0.005715\n",
      "  validation loss:\t\t0.866622\n",
      "  validation accuracy:\t\t81.68 %\n",
      "Epoch 270 of 300 took 1.140s\n",
      "  training loss:\t\t0.006548\n",
      "  validation loss:\t\t0.871729\n",
      "  validation accuracy:\t\t81.23 %\n",
      "Epoch 271 of 300 took 1.140s\n",
      "  training loss:\t\t0.004640\n",
      "  validation loss:\t\t0.861886\n",
      "  validation accuracy:\t\t81.48 %\n",
      "Epoch 272 of 300 took 1.140s\n",
      "  training loss:\t\t0.006186\n",
      "  validation loss:\t\t0.863709\n",
      "  validation accuracy:\t\t81.42 %\n",
      "Epoch 273 of 300 took 1.141s\n",
      "  training loss:\t\t0.007525\n",
      "  validation loss:\t\t0.854900\n",
      "  validation accuracy:\t\t81.23 %\n",
      "Epoch 274 of 300 took 1.142s\n",
      "  training loss:\t\t0.005529\n",
      "  validation loss:\t\t0.854871\n",
      "  validation accuracy:\t\t81.42 %\n",
      "Epoch 275 of 300 took 1.140s\n",
      "  training loss:\t\t0.007859\n",
      "  validation loss:\t\t0.838788\n",
      "  validation accuracy:\t\t81.48 %\n",
      "Epoch 276 of 300 took 1.140s\n",
      "  training loss:\t\t0.006618\n",
      "  validation loss:\t\t0.845090\n",
      "  validation accuracy:\t\t81.23 %\n",
      "Epoch 277 of 300 took 1.140s\n",
      "  training loss:\t\t0.006255\n",
      "  validation loss:\t\t0.862517\n",
      "  validation accuracy:\t\t81.16 %\n",
      "Epoch 278 of 300 took 1.140s\n",
      "  training loss:\t\t0.005665\n",
      "  validation loss:\t\t0.842086\n",
      "  validation accuracy:\t\t81.29 %\n",
      "Epoch 279 of 300 took 1.141s\n",
      "  training loss:\t\t0.006522\n",
      "  validation loss:\t\t0.842562\n",
      "  validation accuracy:\t\t81.68 %\n",
      "Epoch 280 of 300 took 1.140s\n",
      "  training loss:\t\t0.005827\n",
      "  validation loss:\t\t0.834297\n",
      "  validation accuracy:\t\t81.61 %\n",
      "Epoch 281 of 300 took 1.140s\n",
      "  training loss:\t\t0.005295\n",
      "  validation loss:\t\t0.844748\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 282 of 300 took 1.140s\n",
      "  training loss:\t\t0.007400\n",
      "  validation loss:\t\t0.909136\n",
      "  validation accuracy:\t\t81.03 %\n",
      "Epoch 283 of 300 took 1.140s\n",
      "  training loss:\t\t0.005848\n",
      "  validation loss:\t\t0.895973\n",
      "  validation accuracy:\t\t81.10 %\n",
      "Epoch 284 of 300 took 1.140s\n",
      "  training loss:\t\t0.007603\n",
      "  validation loss:\t\t0.848498\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 285 of 300 took 1.140s\n",
      "  training loss:\t\t0.005846\n",
      "  validation loss:\t\t0.851546\n",
      "  validation accuracy:\t\t81.48 %\n",
      "Epoch 286 of 300 took 1.140s\n",
      "  training loss:\t\t0.007471\n",
      "  validation loss:\t\t0.835506\n",
      "  validation accuracy:\t\t81.23 %\n",
      "Epoch 287 of 300 took 1.140s\n",
      "  training loss:\t\t0.006878\n",
      "  validation loss:\t\t0.825502\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 288 of 300 took 1.140s\n",
      "  training loss:\t\t0.007020\n",
      "  validation loss:\t\t0.838547\n",
      "  validation accuracy:\t\t81.55 %\n",
      "Epoch 289 of 300 took 1.140s\n",
      "  training loss:\t\t0.005037\n",
      "  validation loss:\t\t0.845326\n",
      "  validation accuracy:\t\t81.16 %\n",
      "Epoch 290 of 300 took 1.140s\n",
      "  training loss:\t\t0.004847\n",
      "  validation loss:\t\t0.871860\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 291 of 300 took 1.141s\n",
      "  training loss:\t\t0.005455\n",
      "  validation loss:\t\t0.881291\n",
      "  validation accuracy:\t\t81.29 %\n",
      "Epoch 292 of 300 took 1.140s\n",
      "  training loss:\t\t0.005935\n",
      "  validation loss:\t\t0.942597\n",
      "  validation accuracy:\t\t79.48 %\n",
      "Epoch 293 of 300 took 1.140s\n",
      "  training loss:\t\t0.006522\n",
      "  validation loss:\t\t0.840963\n",
      "  validation accuracy:\t\t81.42 %\n",
      "Epoch 294 of 300 took 1.140s\n",
      "  training loss:\t\t0.006289\n",
      "  validation loss:\t\t0.837691\n",
      "  validation accuracy:\t\t81.61 %\n",
      "Epoch 295 of 300 took 1.140s\n",
      "  training loss:\t\t0.006941\n",
      "  validation loss:\t\t0.861482\n",
      "  validation accuracy:\t\t81.61 %\n",
      "Epoch 296 of 300 took 1.140s\n",
      "  training loss:\t\t0.006520\n",
      "  validation loss:\t\t0.868722\n",
      "  validation accuracy:\t\t81.16 %\n",
      "Epoch 297 of 300 took 1.140s\n",
      "  training loss:\t\t0.006726\n",
      "  validation loss:\t\t0.868510\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 298 of 300 took 1.141s\n",
      "  training loss:\t\t0.005711\n",
      "  validation loss:\t\t0.818649\n",
      "  validation accuracy:\t\t81.35 %\n",
      "Epoch 299 of 300 took 1.140s\n",
      "  training loss:\t\t0.005475\n",
      "  validation loss:\t\t0.869368\n",
      "  validation accuracy:\t\t81.42 %\n",
      "Epoch 300 of 300 took 1.140s\n",
      "  training loss:\t\t0.006917\n",
      "  validation loss:\t\t0.838587\n",
      "  validation accuracy:\t\t81.48 %\n",
      "set([0, 1])\n",
      "('TRAIN:', array([   0,    1,    2, ..., 4723, 4724, 4725]), 'TEST:', array([1554, 1555, 1556, ..., 3429, 3438, 3439]))\n",
      "train freq [1575 1575]\n",
      "val freq [788 788]\n",
      "Loading data...\n",
      "Building model and compiling functions...\n",
      "Starting training...\n",
      "Epoch 1 of 300 took 1.140s\n",
      "  training loss:\t\t0.827561\n",
      "  validation loss:\t\t0.684664\n",
      "  validation accuracy:\t\t62.77 %\n",
      "Epoch 2 of 300 took 1.140s\n",
      "  training loss:\t\t0.660506\n",
      "  validation loss:\t\t0.651061\n",
      "  validation accuracy:\t\t63.16 %\n",
      "Epoch 3 of 300 took 1.141s\n",
      "  training loss:\t\t0.644029\n",
      "  validation loss:\t\t0.645345\n",
      "  validation accuracy:\t\t63.55 %\n",
      "Epoch 4 of 300 took 1.141s\n",
      "  training loss:\t\t0.642216\n",
      "  validation loss:\t\t0.644094\n",
      "  validation accuracy:\t\t64.52 %\n",
      "Epoch 5 of 300 took 1.140s\n",
      "  training loss:\t\t0.637977\n",
      "  validation loss:\t\t0.636892\n",
      "  validation accuracy:\t\t64.84 %\n",
      "Epoch 6 of 300 took 1.142s\n",
      "  training loss:\t\t0.633202\n",
      "  validation loss:\t\t0.640913\n",
      "  validation accuracy:\t\t64.84 %\n",
      "Epoch 7 of 300 took 1.141s\n",
      "  training loss:\t\t0.629553\n",
      "  validation loss:\t\t0.631881\n",
      "  validation accuracy:\t\t63.55 %\n",
      "Epoch 8 of 300 took 1.141s\n",
      "  training loss:\t\t0.621400\n",
      "  validation loss:\t\t0.630312\n",
      "  validation accuracy:\t\t65.87 %\n",
      "Epoch 9 of 300 took 1.141s\n",
      "  training loss:\t\t0.617965\n",
      "  validation loss:\t\t0.623702\n",
      "  validation accuracy:\t\t64.90 %\n",
      "Epoch 10 of 300 took 1.141s\n",
      "  training loss:\t\t0.616833\n",
      "  validation loss:\t\t0.622227\n",
      "  validation accuracy:\t\t64.97 %\n",
      "Epoch 11 of 300 took 1.141s\n",
      "  training loss:\t\t0.611508\n",
      "  validation loss:\t\t0.614159\n",
      "  validation accuracy:\t\t65.48 %\n",
      "Epoch 12 of 300 took 1.141s\n",
      "  training loss:\t\t0.600993\n",
      "  validation loss:\t\t0.612048\n",
      "  validation accuracy:\t\t67.81 %\n",
      "Epoch 13 of 300 took 1.141s\n",
      "  training loss:\t\t0.590782\n",
      "  validation loss:\t\t0.608212\n",
      "  validation accuracy:\t\t69.42 %\n",
      "Epoch 14 of 300 took 1.141s\n",
      "  training loss:\t\t0.582190\n",
      "  validation loss:\t\t0.586261\n",
      "  validation accuracy:\t\t68.77 %\n",
      "Epoch 15 of 300 took 1.141s\n",
      "  training loss:\t\t0.575231\n",
      "  validation loss:\t\t0.576815\n",
      "  validation accuracy:\t\t72.65 %\n",
      "Epoch 16 of 300 took 1.141s\n",
      "  training loss:\t\t0.554871\n",
      "  validation loss:\t\t0.553559\n",
      "  validation accuracy:\t\t70.58 %\n",
      "Epoch 17 of 300 took 1.141s\n",
      "  training loss:\t\t0.533429\n",
      "  validation loss:\t\t0.560310\n",
      "  validation accuracy:\t\t74.84 %\n",
      "Epoch 18 of 300 took 1.141s\n",
      "  training loss:\t\t0.515331\n",
      "  validation loss:\t\t0.513175\n",
      "  validation accuracy:\t\t72.84 %\n",
      "Epoch 19 of 300 took 1.142s\n",
      "  training loss:\t\t0.482716\n",
      "  validation loss:\t\t0.495824\n",
      "  validation accuracy:\t\t73.81 %\n",
      "Epoch 20 of 300 took 1.141s\n",
      "  training loss:\t\t0.455531\n",
      "  validation loss:\t\t0.463196\n",
      "  validation accuracy:\t\t79.94 %\n",
      "Epoch 21 of 300 took 1.141s\n",
      "  training loss:\t\t0.421899\n",
      "  validation loss:\t\t0.444124\n",
      "  validation accuracy:\t\t80.06 %\n",
      "Epoch 22 of 300 took 1.141s\n",
      "  training loss:\t\t0.405528\n",
      "  validation loss:\t\t0.426633\n",
      "  validation accuracy:\t\t81.16 %\n",
      "Epoch 23 of 300 took 1.141s\n",
      "  training loss:\t\t0.383274\n",
      "  validation loss:\t\t0.426387\n",
      "  validation accuracy:\t\t80.06 %\n",
      "Epoch 24 of 300 took 1.142s\n",
      "  training loss:\t\t0.355730\n",
      "  validation loss:\t\t0.413018\n",
      "  validation accuracy:\t\t80.71 %\n",
      "Epoch 25 of 300 took 1.142s\n",
      "  training loss:\t\t0.338662\n",
      "  validation loss:\t\t0.400574\n",
      "  validation accuracy:\t\t82.19 %\n",
      "Epoch 26 of 300 took 1.141s\n",
      "  training loss:\t\t0.313728\n",
      "  validation loss:\t\t0.405757\n",
      "  validation accuracy:\t\t81.81 %\n",
      "Epoch 27 of 300 took 1.141s\n",
      "  training loss:\t\t0.301615\n",
      "  validation loss:\t\t0.397904\n",
      "  validation accuracy:\t\t82.65 %\n",
      "Epoch 28 of 300 took 1.141s\n",
      "  training loss:\t\t0.285039\n",
      "  validation loss:\t\t0.388727\n",
      "  validation accuracy:\t\t82.58 %\n",
      "Epoch 29 of 300 took 1.142s\n",
      "  training loss:\t\t0.259295\n",
      "  validation loss:\t\t0.385981\n",
      "  validation accuracy:\t\t82.84 %\n",
      "Epoch 30 of 300 took 1.142s\n",
      "  training loss:\t\t0.252185\n",
      "  validation loss:\t\t0.389006\n",
      "  validation accuracy:\t\t82.65 %\n",
      "Epoch 31 of 300 took 1.141s\n",
      "  training loss:\t\t0.233749\n",
      "  validation loss:\t\t0.390256\n",
      "  validation accuracy:\t\t82.52 %\n",
      "Epoch 32 of 300 took 1.141s\n",
      "  training loss:\t\t0.215709\n",
      "  validation loss:\t\t0.383677\n",
      "  validation accuracy:\t\t83.16 %\n",
      "Epoch 33 of 300 took 1.142s\n",
      "  training loss:\t\t0.194823\n",
      "  validation loss:\t\t0.398078\n",
      "  validation accuracy:\t\t82.90 %\n",
      "Epoch 34 of 300 took 1.142s\n",
      "  training loss:\t\t0.179644\n",
      "  validation loss:\t\t0.393935\n",
      "  validation accuracy:\t\t83.35 %\n",
      "Epoch 35 of 300 took 1.143s\n",
      "  training loss:\t\t0.169571\n",
      "  validation loss:\t\t0.385414\n",
      "  validation accuracy:\t\t83.29 %\n",
      "Epoch 36 of 300 took 1.142s\n",
      "  training loss:\t\t0.163247\n",
      "  validation loss:\t\t0.404614\n",
      "  validation accuracy:\t\t82.84 %\n",
      "Epoch 37 of 300 took 1.142s\n",
      "  training loss:\t\t0.147131\n",
      "  validation loss:\t\t0.399967\n",
      "  validation accuracy:\t\t82.32 %\n",
      "Epoch 38 of 300 took 1.142s\n",
      "  training loss:\t\t0.136583\n",
      "  validation loss:\t\t0.399992\n",
      "  validation accuracy:\t\t83.55 %\n",
      "Epoch 39 of 300 took 1.141s\n",
      "  training loss:\t\t0.118255\n",
      "  validation loss:\t\t0.400917\n",
      "  validation accuracy:\t\t82.65 %\n",
      "Epoch 40 of 300 took 1.142s\n",
      "  training loss:\t\t0.117395\n",
      "  validation loss:\t\t0.405409\n",
      "  validation accuracy:\t\t82.77 %\n",
      "Epoch 41 of 300 took 1.141s\n",
      "  training loss:\t\t0.107086\n",
      "  validation loss:\t\t0.412906\n",
      "  validation accuracy:\t\t82.45 %\n",
      "Epoch 42 of 300 took 1.142s\n",
      "  training loss:\t\t0.099179\n",
      "  validation loss:\t\t0.409905\n",
      "  validation accuracy:\t\t83.03 %\n",
      "Epoch 43 of 300 took 1.141s\n",
      "  training loss:\t\t0.090465\n",
      "  validation loss:\t\t0.426072\n",
      "  validation accuracy:\t\t83.61 %\n",
      "Epoch 44 of 300 took 1.141s\n",
      "  training loss:\t\t0.085138\n",
      "  validation loss:\t\t0.442519\n",
      "  validation accuracy:\t\t83.35 %\n",
      "Epoch 45 of 300 took 1.142s\n",
      "  training loss:\t\t0.076325\n",
      "  validation loss:\t\t0.453630\n",
      "  validation accuracy:\t\t82.00 %\n",
      "Epoch 46 of 300 took 1.142s\n",
      "  training loss:\t\t0.070637\n",
      "  validation loss:\t\t0.440699\n",
      "  validation accuracy:\t\t83.03 %\n",
      "Epoch 47 of 300 took 1.141s\n",
      "  training loss:\t\t0.065248\n",
      "  validation loss:\t\t0.444222\n",
      "  validation accuracy:\t\t82.77 %\n",
      "Epoch 48 of 300 took 1.141s\n",
      "  training loss:\t\t0.060438\n",
      "  validation loss:\t\t0.448732\n",
      "  validation accuracy:\t\t82.97 %\n",
      "Epoch 49 of 300 took 1.141s\n",
      "  training loss:\t\t0.057592\n",
      "  validation loss:\t\t0.453717\n",
      "  validation accuracy:\t\t83.03 %\n",
      "Epoch 50 of 300 took 1.141s\n",
      "  training loss:\t\t0.053204\n",
      "  validation loss:\t\t0.467920\n",
      "  validation accuracy:\t\t82.39 %\n",
      "Epoch 51 of 300 took 1.141s\n",
      "  training loss:\t\t0.046012\n",
      "  validation loss:\t\t0.481121\n",
      "  validation accuracy:\t\t82.52 %\n",
      "Epoch 52 of 300 took 1.141s\n",
      "  training loss:\t\t0.049308\n",
      "  validation loss:\t\t0.495297\n",
      "  validation accuracy:\t\t82.65 %\n",
      "Epoch 53 of 300 took 1.141s\n",
      "  training loss:\t\t0.047190\n",
      "  validation loss:\t\t0.484460\n",
      "  validation accuracy:\t\t82.97 %\n",
      "Epoch 54 of 300 took 1.141s\n",
      "  training loss:\t\t0.039424\n",
      "  validation loss:\t\t0.507702\n",
      "  validation accuracy:\t\t81.68 %\n",
      "Epoch 55 of 300 took 1.141s\n",
      "  training loss:\t\t0.035345\n",
      "  validation loss:\t\t0.503817\n",
      "  validation accuracy:\t\t82.65 %\n",
      "Epoch 56 of 300 took 1.141s\n",
      "  training loss:\t\t0.038723\n",
      "  validation loss:\t\t0.505353\n",
      "  validation accuracy:\t\t82.84 %\n",
      "Epoch 57 of 300 took 1.141s\n",
      "  training loss:\t\t0.032696\n",
      "  validation loss:\t\t0.511134\n",
      "  validation accuracy:\t\t82.65 %\n",
      "Epoch 58 of 300 took 1.141s\n",
      "  training loss:\t\t0.031317\n",
      "  validation loss:\t\t0.517260\n",
      "  validation accuracy:\t\t82.32 %\n",
      "Epoch 59 of 300 took 1.142s\n",
      "  training loss:\t\t0.030552\n",
      "  validation loss:\t\t0.528534\n",
      "  validation accuracy:\t\t82.26 %\n",
      "Epoch 60 of 300 took 1.141s\n",
      "  training loss:\t\t0.029243\n",
      "  validation loss:\t\t0.535684\n",
      "  validation accuracy:\t\t82.13 %\n",
      "Epoch 61 of 300 took 1.142s\n",
      "  training loss:\t\t0.027977\n",
      "  validation loss:\t\t0.539878\n",
      "  validation accuracy:\t\t82.00 %\n",
      "Epoch 62 of 300 took 1.141s\n",
      "  training loss:\t\t0.026842\n",
      "  validation loss:\t\t0.555221\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 63 of 300 took 1.141s\n",
      "  training loss:\t\t0.029514\n",
      "  validation loss:\t\t0.530154\n",
      "  validation accuracy:\t\t82.39 %\n",
      "Epoch 64 of 300 took 1.142s\n",
      "  training loss:\t\t0.024686\n",
      "  validation loss:\t\t0.546916\n",
      "  validation accuracy:\t\t82.19 %\n",
      "Epoch 65 of 300 took 1.141s\n",
      "  training loss:\t\t0.022460\n",
      "  validation loss:\t\t0.563226\n",
      "  validation accuracy:\t\t82.84 %\n",
      "Epoch 66 of 300 took 1.141s\n",
      "  training loss:\t\t0.021805\n",
      "  validation loss:\t\t0.561885\n",
      "  validation accuracy:\t\t82.65 %\n",
      "Epoch 67 of 300 took 1.143s\n",
      "  training loss:\t\t0.020988\n",
      "  validation loss:\t\t0.580005\n",
      "  validation accuracy:\t\t82.52 %\n",
      "Epoch 68 of 300 took 1.142s\n",
      "  training loss:\t\t0.022735\n",
      "  validation loss:\t\t0.576314\n",
      "  validation accuracy:\t\t82.13 %\n",
      "Epoch 69 of 300 took 1.142s\n",
      "  training loss:\t\t0.019862\n",
      "  validation loss:\t\t0.571635\n",
      "  validation accuracy:\t\t81.81 %\n",
      "Epoch 70 of 300 took 1.141s\n",
      "  training loss:\t\t0.018787\n",
      "  validation loss:\t\t0.580947\n",
      "  validation accuracy:\t\t82.58 %\n",
      "Epoch 71 of 300 took 1.141s\n",
      "  training loss:\t\t0.021547\n",
      "  validation loss:\t\t0.573536\n",
      "  validation accuracy:\t\t82.06 %\n",
      "Epoch 72 of 300 took 1.141s\n",
      "  training loss:\t\t0.021116\n",
      "  validation loss:\t\t0.578744\n",
      "  validation accuracy:\t\t82.45 %\n",
      "Epoch 73 of 300 took 1.141s\n",
      "  training loss:\t\t0.022459\n",
      "  validation loss:\t\t0.592652\n",
      "  validation accuracy:\t\t83.16 %\n",
      "Epoch 74 of 300 took 1.142s\n",
      "  training loss:\t\t0.021481\n",
      "  validation loss:\t\t0.584813\n",
      "  validation accuracy:\t\t82.71 %\n",
      "Epoch 75 of 300 took 1.141s\n",
      "  training loss:\t\t0.020584\n",
      "  validation loss:\t\t0.601822\n",
      "  validation accuracy:\t\t82.71 %\n",
      "Epoch 76 of 300 took 1.142s\n",
      "  training loss:\t\t0.017529\n",
      "  validation loss:\t\t0.607275\n",
      "  validation accuracy:\t\t82.84 %\n",
      "Epoch 77 of 300 took 1.141s\n",
      "  training loss:\t\t0.015485\n",
      "  validation loss:\t\t0.629745\n",
      "  validation accuracy:\t\t82.90 %\n",
      "Epoch 78 of 300 took 1.142s\n",
      "  training loss:\t\t0.016757\n",
      "  validation loss:\t\t0.636413\n",
      "  validation accuracy:\t\t82.97 %\n",
      "Epoch 79 of 300 took 1.141s\n",
      "  training loss:\t\t0.017721\n",
      "  validation loss:\t\t0.604847\n",
      "  validation accuracy:\t\t82.65 %\n",
      "Epoch 80 of 300 took 1.141s\n",
      "  training loss:\t\t0.016634\n",
      "  validation loss:\t\t0.611767\n",
      "  validation accuracy:\t\t82.45 %\n",
      "Epoch 81 of 300 took 1.141s\n",
      "  training loss:\t\t0.018074\n",
      "  validation loss:\t\t0.617858\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 82 of 300 took 1.141s\n",
      "  training loss:\t\t0.017635\n",
      "  validation loss:\t\t0.608302\n",
      "  validation accuracy:\t\t81.81 %\n",
      "Epoch 83 of 300 took 1.141s\n",
      "  training loss:\t\t0.015023\n",
      "  validation loss:\t\t0.628826\n",
      "  validation accuracy:\t\t82.90 %\n",
      "Epoch 84 of 300 took 1.141s\n",
      "  training loss:\t\t0.018367\n",
      "  validation loss:\t\t0.625186\n",
      "  validation accuracy:\t\t81.68 %\n",
      "Epoch 85 of 300 took 1.141s\n",
      "  training loss:\t\t0.016349\n",
      "  validation loss:\t\t0.618133\n",
      "  validation accuracy:\t\t82.52 %\n",
      "Epoch 86 of 300 took 1.142s\n",
      "  training loss:\t\t0.015419\n",
      "  validation loss:\t\t0.637431\n",
      "  validation accuracy:\t\t82.19 %\n",
      "Epoch 87 of 300 took 1.141s\n",
      "  training loss:\t\t0.013087\n",
      "  validation loss:\t\t0.621969\n",
      "  validation accuracy:\t\t82.58 %\n",
      "Epoch 88 of 300 took 1.141s\n",
      "  training loss:\t\t0.016146\n",
      "  validation loss:\t\t0.640920\n",
      "  validation accuracy:\t\t81.94 %\n",
      "Epoch 89 of 300 took 1.141s\n",
      "  training loss:\t\t0.016136\n",
      "  validation loss:\t\t0.660821\n",
      "  validation accuracy:\t\t82.58 %\n",
      "Epoch 90 of 300 took 1.141s\n",
      "  training loss:\t\t0.015652\n",
      "  validation loss:\t\t0.633678\n",
      "  validation accuracy:\t\t82.32 %\n",
      "Epoch 91 of 300 took 1.141s\n",
      "  training loss:\t\t0.015740\n",
      "  validation loss:\t\t0.640397\n",
      "  validation accuracy:\t\t82.06 %\n",
      "Epoch 92 of 300 took 1.141s\n",
      "  training loss:\t\t0.011561\n",
      "  validation loss:\t\t0.648913\n",
      "  validation accuracy:\t\t82.32 %\n",
      "Epoch 93 of 300 took 1.141s\n",
      "  training loss:\t\t0.016031\n",
      "  validation loss:\t\t0.673474\n",
      "  validation accuracy:\t\t82.19 %\n",
      "Epoch 94 of 300 took 1.141s\n",
      "  training loss:\t\t0.012416\n",
      "  validation loss:\t\t0.644032\n",
      "  validation accuracy:\t\t82.39 %\n",
      "Epoch 95 of 300 took 1.142s\n",
      "  training loss:\t\t0.016507\n",
      "  validation loss:\t\t0.642371\n",
      "  validation accuracy:\t\t81.94 %\n",
      "Epoch 96 of 300 took 1.141s\n",
      "  training loss:\t\t0.013163\n",
      "  validation loss:\t\t0.662936\n",
      "  validation accuracy:\t\t82.19 %\n",
      "Epoch 97 of 300 took 1.141s\n",
      "  training loss:\t\t0.014075\n",
      "  validation loss:\t\t0.662515\n",
      "  validation accuracy:\t\t82.39 %\n",
      "Epoch 98 of 300 took 1.142s\n",
      "  training loss:\t\t0.013686\n",
      "  validation loss:\t\t0.662826\n",
      "  validation accuracy:\t\t82.77 %\n",
      "Epoch 99 of 300 took 1.141s\n",
      "  training loss:\t\t0.014924\n",
      "  validation loss:\t\t0.658332\n",
      "  validation accuracy:\t\t82.32 %\n",
      "Epoch 100 of 300 took 1.141s\n",
      "  training loss:\t\t0.011402\n",
      "  validation loss:\t\t0.692022\n",
      "  validation accuracy:\t\t82.39 %\n",
      "Epoch 101 of 300 took 1.141s\n",
      "  training loss:\t\t0.011498\n",
      "  validation loss:\t\t0.658262\n",
      "  validation accuracy:\t\t82.32 %\n",
      "Epoch 102 of 300 took 1.141s\n",
      "  training loss:\t\t0.011411\n",
      "  validation loss:\t\t0.647407\n",
      "  validation accuracy:\t\t82.32 %\n",
      "Epoch 103 of 300 took 1.142s\n",
      "  training loss:\t\t0.011647\n",
      "  validation loss:\t\t0.657572\n",
      "  validation accuracy:\t\t82.45 %\n",
      "Epoch 104 of 300 took 1.141s\n",
      "  training loss:\t\t0.011451\n",
      "  validation loss:\t\t0.683830\n",
      "  validation accuracy:\t\t82.45 %\n",
      "Epoch 105 of 300 took 1.141s\n",
      "  training loss:\t\t0.014022\n",
      "  validation loss:\t\t0.675602\n",
      "  validation accuracy:\t\t82.71 %\n",
      "Epoch 106 of 300 took 1.141s\n",
      "  training loss:\t\t0.015949\n",
      "  validation loss:\t\t0.654144\n",
      "  validation accuracy:\t\t82.84 %\n",
      "Epoch 107 of 300 took 1.141s\n",
      "  training loss:\t\t0.011813\n",
      "  validation loss:\t\t0.672056\n",
      "  validation accuracy:\t\t82.06 %\n",
      "Epoch 108 of 300 took 1.141s\n",
      "  training loss:\t\t0.012287\n",
      "  validation loss:\t\t0.717759\n",
      "  validation accuracy:\t\t82.06 %\n",
      "Epoch 109 of 300 took 1.143s\n",
      "  training loss:\t\t0.009853\n",
      "  validation loss:\t\t0.688590\n",
      "  validation accuracy:\t\t81.94 %\n",
      "Epoch 110 of 300 took 1.141s\n",
      "  training loss:\t\t0.012663\n",
      "  validation loss:\t\t0.675128\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 111 of 300 took 1.141s\n",
      "  training loss:\t\t0.009766\n",
      "  validation loss:\t\t0.702378\n",
      "  validation accuracy:\t\t82.45 %\n",
      "Epoch 112 of 300 took 1.141s\n",
      "  training loss:\t\t0.012250\n",
      "  validation loss:\t\t0.682763\n",
      "  validation accuracy:\t\t82.39 %\n",
      "Epoch 113 of 300 took 1.141s\n",
      "  training loss:\t\t0.013693\n",
      "  validation loss:\t\t0.686430\n",
      "  validation accuracy:\t\t82.00 %\n",
      "Epoch 114 of 300 took 1.141s\n",
      "  training loss:\t\t0.010718\n",
      "  validation loss:\t\t0.685292\n",
      "  validation accuracy:\t\t82.13 %\n",
      "Epoch 115 of 300 took 1.141s\n",
      "  training loss:\t\t0.011502\n",
      "  validation loss:\t\t0.670265\n",
      "  validation accuracy:\t\t82.19 %\n",
      "Epoch 116 of 300 took 1.141s\n",
      "  training loss:\t\t0.009736\n",
      "  validation loss:\t\t0.710344\n",
      "  validation accuracy:\t\t82.00 %\n",
      "Epoch 117 of 300 took 1.141s\n",
      "  training loss:\t\t0.008138\n",
      "  validation loss:\t\t0.721192\n",
      "  validation accuracy:\t\t82.39 %\n",
      "Epoch 118 of 300 took 1.141s\n",
      "  training loss:\t\t0.011777\n",
      "  validation loss:\t\t0.753922\n",
      "  validation accuracy:\t\t82.45 %\n",
      "Epoch 119 of 300 took 1.141s\n",
      "  training loss:\t\t0.013285\n",
      "  validation loss:\t\t0.757976\n",
      "  validation accuracy:\t\t81.87 %\n",
      "Epoch 120 of 300 took 1.141s\n",
      "  training loss:\t\t0.011404\n",
      "  validation loss:\t\t0.827489\n",
      "  validation accuracy:\t\t81.68 %\n",
      "Epoch 121 of 300 took 1.141s\n",
      "  training loss:\t\t0.013708\n",
      "  validation loss:\t\t0.686188\n",
      "  validation accuracy:\t\t82.13 %\n",
      "Epoch 122 of 300 took 1.141s\n",
      "  training loss:\t\t0.009360\n",
      "  validation loss:\t\t0.735296\n",
      "  validation accuracy:\t\t81.48 %\n",
      "Epoch 123 of 300 took 1.141s\n",
      "  training loss:\t\t0.010379\n",
      "  validation loss:\t\t0.741058\n",
      "  validation accuracy:\t\t80.39 %\n",
      "Epoch 124 of 300 took 1.141s\n",
      "  training loss:\t\t0.012207\n",
      "  validation loss:\t\t0.691847\n",
      "  validation accuracy:\t\t82.26 %\n",
      "Epoch 125 of 300 took 1.141s\n",
      "  training loss:\t\t0.012778\n",
      "  validation loss:\t\t0.714594\n",
      "  validation accuracy:\t\t81.68 %\n",
      "Epoch 126 of 300 took 1.141s\n",
      "  training loss:\t\t0.010325\n",
      "  validation loss:\t\t0.778195\n",
      "  validation accuracy:\t\t82.32 %\n",
      "Epoch 127 of 300 took 1.141s\n",
      "  training loss:\t\t0.008777\n",
      "  validation loss:\t\t0.814512\n",
      "  validation accuracy:\t\t80.32 %\n",
      "Epoch 128 of 300 took 1.141s\n",
      "  training loss:\t\t0.012065\n",
      "  validation loss:\t\t0.713023\n",
      "  validation accuracy:\t\t82.00 %\n",
      "Epoch 129 of 300 took 1.198s\n",
      "  training loss:\t\t0.008436\n",
      "  validation loss:\t\t0.742713\n",
      "  validation accuracy:\t\t82.00 %\n",
      "Epoch 130 of 300 took 1.180s\n",
      "  training loss:\t\t0.010132\n",
      "  validation loss:\t\t0.715715\n",
      "  validation accuracy:\t\t82.26 %\n",
      "Epoch 131 of 300 took 1.159s\n",
      "  training loss:\t\t0.010650\n",
      "  validation loss:\t\t0.705690\n",
      "  validation accuracy:\t\t81.74 %\n",
      "Epoch 132 of 300 took 1.180s\n",
      "  training loss:\t\t0.011906\n",
      "  validation loss:\t\t0.723068\n",
      "  validation accuracy:\t\t81.61 %\n",
      "Epoch 133 of 300 took 1.164s\n",
      "  training loss:\t\t0.009797\n",
      "  validation loss:\t\t0.755017\n",
      "  validation accuracy:\t\t81.42 %\n",
      "Epoch 134 of 300 took 1.141s\n",
      "  training loss:\t\t0.008521\n",
      "  validation loss:\t\t0.750633\n",
      "  validation accuracy:\t\t81.68 %\n",
      "Epoch 135 of 300 took 1.153s\n",
      "  training loss:\t\t0.011751\n",
      "  validation loss:\t\t0.695106\n",
      "  validation accuracy:\t\t81.61 %\n",
      "Epoch 136 of 300 took 1.145s\n",
      "  training loss:\t\t0.007471\n",
      "  validation loss:\t\t0.747947\n",
      "  validation accuracy:\t\t82.39 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-43ba018e1687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"val freq\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-f1c92f8ba6ca>\u001b[0m in \u001b[0;36mtrain_cnn\u001b[0;34m(X_train, y_train, X_val, y_val, X_test, num_epochs)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mtrain_err\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mtrain_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, val_index in skf.split(data, label):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", val_index)\n",
    "    data_train, data_val = data[train_index], data[val_index]\n",
    "    label_train, label_val = label[train_index], label[val_index]\n",
    "    \n",
    "    freq_train = itemfreq(label_train)\n",
    "    print \"train freq\", freq_train[:,1]\n",
    "    freq_val = itemfreq(label_val)\n",
    "    print \"val freq\", freq_val[:,1]\n",
    "    \n",
    "    train_cnn(data_train, label_train, data_val, label_val, data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
